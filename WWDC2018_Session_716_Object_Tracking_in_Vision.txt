안녕하세요, 여러분, Vision 세션의 Object Tracking에 오신 것을 환영합니다.
 다양한 컴퓨터 비전 문제를 직면하고 해결해야합니까? 그렇다면 Mac 및 iOS, 또는 개발자로서의 각자가 올바른 위치에 있는지.
 내 이름은 Sergey Kamensky입니다.
 Vision Framework가 어떻게 도움이되는지 알려 드리게되어 기쁩니다.
 우리의 의제는 오늘 네 가지 항목으로 구성됩니다.
 먼저 우리는 왜 비전에 대해서 이야기 할 것입니까? 둘째, 우리는 올해 우리가 소개하고있는 새로운 것이 있는지 살펴볼 것입니다.
 셋째,이 Vision API 전반에 걸쳐보다 깊이있는 다이빙을 할 것입니다.
 그리고 마침내, 우리는 프레젠테이션의 주요 주제 인 비전 추적 (Tracking in Vision)으로 이동하게 될 것입니다.
 그렇다면 비전은 무엇입니까? 우리는 프레임 워크를 설계 할 때 처음으로 간단하고 일관성있는 인터페이스, 하나의 멀티 플랫폼에서 모든 컴퓨터 비전 문제를 해결하기위한 하나의 중심지 였으면합니다. 우리의 프레임 워크는 iOS, macOS 및 tvOS에서 실행됩니다.
 우리는 개인 정보 보호에 중점을두고 있습니다.
 이것이 의미하는 바는 데이터가 절대로 장치를 떠나지 않는다는 것입니다.
 [인식 할 수없는] 모든 동기화는 로컬이며, 우리는 지속적으로 작업하고 있습니다.
 우리는 기존의 알고리즘을 향상시키고 있으며 새로운 알고리즘을 개발 중입니다.
 비전 기본 사항을 살펴 보겠습니다.
 Vision API와 상호 작용하는 방법을 생각할 때,이 용어, 처리 대상, 처리 방법 및 결과를 찾는 위치에 대해 생각해 보시기 바랍니다.
 처리 할 대상은 요청에 관한 것입니다.
 그것이 당신이 원하는 것을 우리에게 말하는 방식입니다.
 요청 처리기 또는 엔진 (요청 처리기)은 요청을 처리하는 데 사용됩니다.
 그리고 마지막으로, 결과; 비전의 결과는 관찰의 형태로옵니다.
 이 슬라이드를 살펴보십시오.
 이 프리젠 테이션에서 무엇을 기억해야한다면이 슬라이드는 아마도 더 중요한 슬라이드 중 하나 일 것입니다.
 이 슬라이드는 철학, 비전과 상호 작용하는 방법, 요청, 처리기 요청 및 관찰을 제공합니다.
 먼저 요청을 살펴 보겠습니다.
 이것은 우리가 오늘 제공하는 요청 모음입니다.
 보시다시피, 우리는 다양한 탐지기를 가지고 있습니다.
 이미지 등록 요청이 있습니다.
 두 개의 추적기가 있으며 CoreML 요청이 있습니다.
 Vision과 CoreML의 통합에 대해 더 자세히 알고 싶다면 내 동료 Fran가이 통합의 세부 사항을 다루는이 세션의 다음 세션으로 초대합니다.
 요청 처리기를 살펴 보겠습니다.
 비전에는 두 가지가 있습니다.
 이미지 요청 처리기가 있으며 시퀀스 요청 처리기가 있습니다.
 이 기준을 사용하여 두 가지를 비교해 보겠습니다.
 먼저 Image Request Handler를 살펴 보겠습니다.
 이미지 요청 처리기는 동일한 이미지에서 하나 이상의 요청을 처리하는 데 사용됩니다.
 그것이 말하지 않는 것, 이미지 파생물 및 게시 요청 결과와 같은 특정 정보를 캐시합니다.
 따라서 파이프 라인의 다른 요청은 해당 정보를 사용할 수 있습니다.
 내가 너에게 모범을 보이 겠어.
 요청이 신경망을 실행하는 것에 달려있는 경우, 신경망은 특정 크기 및 특정 색 구성표의 이미지를 기대합니다.
 당신의 신경망이 500 x 500의 흑백을 기대한다고 가정 해 봅시다.
 그 형식으로 사용자 입력을받는 것은 매우 드뭅니다.
 그러면 내부에서 무엇을 할 지, 이미지를 변환 할 것입니다.
 현재 요청에 대한 결과를 얻기 위해 신경망에 입력하지만, 요청 처리기 객체에 해당 정보를 캐시합니다.
 따라서 다음 요청은 동일한 형식을 사용해야하는 경우 이미 존재하며 다시 계산할 필요가 없습니다.
 또한 요청에서 얻은 결과를 다른 요청에서 파이프 라인에서 사용할 수 있도록 캐시 할 것이므로이 프레젠테이션에서 앞으로 진행할 파이프 라인을 살펴볼 것입니다.
 Sequence Request Handler를 살펴 보겠습니다.
 시퀀스 요청 핸들러는 일련의 프레임에서 추적과 같은 특정 작업을 처리하는 데 사용됩니다.
 내부에서 무엇을하는지, 그것은 전체 시퀀스의 프레임에서 프레임으로 작업의 상태를 캐시합니다.
 비전에서는 추적 및 이미지 등록 요청을 처리하는 데 사용됩니다.
 다른 모든 요청은 이미지 요청 처리기로 처리됩니다.
 결과를 살펴 보겠습니다.
 비전의 결과는 관찰 결과입니다.
 Observations는 VNObservation 클래스에서 파생 된 클래스 모음입니다.
 우리는 어떻게 관찰을합니까? 우선, 가장 자연스러운 방법은 요청이 처리 될 때 그 요청의 results 속성을 살펴보고 결과 속성이 관측 값의 집합이라는 것입니다.
 이것이 우리가 처리 결과를 알려주는 방법입니다.
 두 번째 방법은 수동으로 생성하는 것입니다.
 우리는 다른 프리젠 테이션을위한 예제들을 살펴볼 것입니다.
 올해 새로운 것을 보도록하겠습니다.
 첫째, 새로운 얼굴 검출기가 있습니다.
 이제 우리는 더 많은 얼굴을 탐지 할 수 있으며, 이제 우리는 방향에 구애받지 않습니다.
 예를 봅시다.
 왼쪽에는 7 개의 얼굴이있는 이미지를 볼 수 있으며 작년부터 감지기로 이미지를 처리 ​​할 수 ​​있으며 3 개의 얼굴 만 감지 할 수 있으며 그 얼굴은 직립에 가까운 얼굴입니다 위치.

올해 들어오는 얼굴 검출기로 동일한 이미지를 처리하면 볼 수 있듯이 모든 얼굴을 감지 할 수 있으며 더 이상 방향이 문제가되지 않습니다.
 세부 사항을 조금 더 살펴 보겠습니다.
 고맙습니다.
 그래서, 우리의 새로운 얼굴 탐지기는 작년과 같은 API를 사용합니다.
 유일한 차이점은 수정 버전을 지정하려는 경우 해당 요청의 수정 속성을 덮어 쓰고 명시 적으로 User Vision # 2로 설정해야한다는 것입니다.
 다시 한 번 다음 슬라이드에서 이유를 설명하겠습니다.
 또한 두 가지 새로운 속성을 도입했습니다.
 하나는 롤입니다. 이것은 머리가 이처럼 회전 할 때, 다른 하나는 머리가 목 주위를 돌 때 yaw입니다.
 수정.
 새로운 알고리즘을 도입 할 필요가있을 때 Vision에서 어떤 일이 발생했는지, 우리는 이전 알고리즘을 즉시 중단합니다.
 대신, 우리는 어느 정도 수정하거나, 앞으로 나아가고, 더 많이 동시에 진행할 것입니다.
 요청의 개정 속성을 지정하여 작업 할 작업을 지정하십시오.
 그래서 그것은 명백한 행동입니다.
 그러나 기본 동작도 있습니다.
 요청 객체를 만들고 아무 것도 알려주지 않고 요청 처리를 시작하면 다음과 같은 일이 발생합니다.
 기본적으로 앱과 연결된 SDK의 최신 앱 수정 버전을 받고 있습니다.
 이것은 이해하는 것이 중요하며, 나는 당신에게 모범을 보일 것입니다.
 작년의 SDK가 앱과 연결되어 있다고 가정 해 보겠습니다.
 작년에 우리는 단 하나의 탐지기 만 가지고있었습니다.
 따라서,이 앱을 가져 와서 편집하지 않고도 현재 운영 체제에서 실행하더라도 감지기입니다.
 반면에 한 줄이나 좌표를 변경하지 않고 현재 SDK로 앱을 다시 컴파일하고 현재 OS에서 실행하면 기본적으로 버전 # 2를 얻게됩니다. 현재의 SDK
 우리는 귀하의 앱을 미래 보장 할 것을 강력히 권장하지만 비전에 독점적입니다.
 당신이 얻는 것은, 먼저 결정론적인 행동을 취하는 것입니다.
 당신은 인용하고있는 알고리즘의 성능을 알고 있습니다.
 당신은 무엇을 기대해야하는지 압니다.
 또한 우리는 몇 년 후와 같이 특정 개정 내용을 향후에 비난한다면 미래의 증거로 앱을 만들 수 있습니다. 예를 들어, 향후 몇 년이 지나면 [안 들림] ] 오늘.
 Vision API와 상호 작용하는 방법에 대해 자세히 살펴 보겠습니다.
 먼저 Image Request Handler를 사용하여 예제를 살펴 보겠습니다.
 따라서 이미지 요청 처리기는 동일한 이미지에서 하나 이상의 요청을 처리하는 데 사용됩니다.
 이미지 파생물 및 요청 결과와 같은 일부 정보를 캐싱하여 최적화되었습니다.
 따라서 처리 할 연속 요청에이 정보를 사용할 수 있습니다.
 코드 샘플을 살펴 보겠습니다.
 코드 샘플을 살펴보기 전에이 프레젠테이션의 코드 샘플에 대해 몇 가지 핵심만을 강조하고자합니다.
 오류 처리는 오류를 처리하는 좋은 예가 아닙니다.
 try의 짧은 버전을 사용하며 [들리지 않음]을 사용합니다.
 이는 예제를 단순화하기위한 것입니다.
 앱을 코딩 할 때 원치 않는 행동으로부터 보호하기 위해 경비원을 사용해야합니다.
 또한 이미지 요청 처리기 개체를 만들 때 이미지 URL을 사용합니다. 이는 파일이있는 SSD의 장소 일뿐입니다.
 자, 예제를 보자.
 먼저, 감지 얼굴 요청 객체를 생성 할 것입니다.
 그런 다음 이미지 요청 처리기를 만들어 얼굴이있는 이미지의 파일과 이미지 URL을 전달합니다.
 그런 다음 요청 처리기에 요청 처리기에 요청할 것입니다.
 그리고 마지막으로 결과를 살펴 보겠습니다.
 아주 간단합니다.
 그 안에 하나의 얼굴이있는 이미지가 있으면 내 결과는 다음과 같을 것입니다.
 그래서, 내가 무엇을 되 찾을 까? 얼굴 관찰 객체를 다시 얻습니다. 그 객체의 더 중요한 필드 중 하나는 얼굴이있는 경계 상자입니다.
 이 슬라이드를 다시 한 번 살펴 보겠습니다.
 처음 세 줄은 이미지의 모든 얼굴을 찾는 데 필요한 모든 것입니다.
 멋지지 않니? 이제 Sequence Request Handler를 살펴 보겠습니다.
 음, 시퀀스 요청 핸들러는 기억하고 있듯이 일련의 프레임을 추적하는 것과 같은 특정 작업을 처리하는 데 사용됩니다.
 코드 샘플을 살펴 보겠습니다.이 코드 샘플은 Vision API로 상상할 수있는 가장 간단한 추적 시퀀스입니다.
 먼저 Sequence Request Handler를 생성 할 것입니다.
 그런 다음 추적 할 객체를 지정해야하며, 감지 된 객체 관측치를 작성하여 매개 변수 위치, 경계 상자를 얻습니다.
 그런 다음 추적 신호를 시작하겠습니다.
 이 예제에서는 5 개의 연속 프레임에 대해 객체를 추적 할 것입니다.
 시퀀스가 어떻게 작동하는지 살펴 보겠습니다.
 첫째, 프레임 피드 객체가 있습니다. 예를 들어, 카메라 피드와 같을 수 있습니다.
 이것은 내 프레임을 얻는 곳입니다.

내 프레임을 얻으면 요청 객체를 만들고 초기화 된 객체 관찰을 매개 변수로 전달합니다.
 그리고 이것은 루프가 시작되기 전에 방금 만든 것입니다.
 그런 다음 요청 처리기에 요청 처리기에 요청할 것입니다.
 결과를 살펴보고 결과를 분석하고 그 결과를보고해야하는 곳입니다.
 그리고 마지막 단계는 매우 중요합니다. 여기서 내가하고있는 일은 현재 반복에서 결과를 가져오고 다음 반복에 전달할 것입니다.
 따라서 다음 반복 요청이 생성되면 그 결과를 내부에서보고 싶습니다.
 5 프레임 연속으로 원한다면 내 결과는 다음과 같을 것입니다.
 요청 개체를 만드는 방법.
 우선, 우리 요청에는 두 가지 유형의 속성이 있다는 것을 이해하는 것이 중요합니다.
 필수 속성이 있으며 선택적 속성이 있습니다.
 이름에서 알 수 있듯이 필수 속성은 요청 개체를 만들 수 있도록 이니셜 라이저를 통해 제공해야합니다.
 예제를 살펴 보겠습니다.
 이전 슬라이드에는 그냥 들어가는 내용이 있습니다.
 [들리지 않음] 객체 요청의 초기화 프로그램으로 전달되는 객체 관찰이 필수 속성의 예입니다.
 또한 선택적 속성이 있습니다.
 그런데 두 가지 유형의 속성이 선언됩니다.
 요청 개체가 선언 된 위치에서 찾을 수 있습니다.
 선택적 속성은 의미있는 기본값이있는 별도의 속성입니다.
 따라서 우리는 초기화 할 것이지만 나중에 필요할 때 덮어 쓸 수 있습니다.
 예제를 살펴 보겠습니다.
 내가 여기서하고있는 일은 바코드 요청 객체를 감지하지 못하게하는 것입니다.
 다른 작업을 수행하지 않고 요청 객체를 가져 와서 요청 처리기에 제공하면 바코드를 찾고 전체 이미지 작업을 수행하게됩니다.
 대신 여기에서 할 일은 중앙 속성 이미지와 같은 작은 부분을 지정하는 것입니다.
 바코드를 찾는 데 집중하고 싶은 부분이 있습니다. 관심 영역의 영역을 덮어 쓰겠습니다.
 요청 개체를 가져 와서 요청 처리기로 가져 오는 경우 이미지의 더 작은 부분에만 초점을 맞출 것입니다.
 관심 영역 속성은 여기에있는 선택적 속성의 예입니다.
 요청 객체를 손에 넣으면 완전히 구성된 객체라는 점도 이해해야합니다.
 객체를 만들 때마다 작업을 시작할 수있는 객체입니다.
 나중에 특정 속성을 덮어 쓰기로 결정했다면 그렇게 할 수 있습니다.
 그러나 당신이 물건을 가지고있을 때마다, 당신이 함께 일할 수있는 물건입니다.
 다음 슬라이드에서 더 자세히 설명 할이 슬라이드의 한 가지 사항은 테두리 상자를 보는 것입니다.
 보시다시피, 우리가받는 좌표는 정규화됩니다.
 그들은 0에서 1까지이고 그들은 항상 왼쪽 하단 모서리를 기준으로합니다.
 다음 세션 인 CoreML과 Vision의 통합은이 부분을보다 자세히 설명합니다.
 결과를 이해하는 방법을 살펴 보겠습니다.
 우리가 말했듯이, 비전의 결과는 관찰의 형태로옵니다.
 관측치는 요청 개체의 results 속성을 통해 채워집니다.
 얼마나 많은 관찰을 할 수 있습니까? 모든 콜렉션은 0에서 N까지입니다.
 여기에 또 하나의 측면이 있습니다.
 결과를 nil로 설정하면 [들리지 않음] 단일 요청이 실패했음을 의미합니다.
 이는 0 회의 관측치가 충족되는 것과는 다릅니다.
 0 회의 관측 결과를 얻는 것은 당신이 찾고 있던 것이 무엇이든 그곳에 있지 않다는 것을 의미합니다.
 예를 들어, 얼굴 검출기를 실행한다고합시다.
 얼굴이없는 이미지를 자연스럽게 먹이면 0 회의 관측이 이루어집니다.
 다른 한편, 이미지에 하나 이상의 얼굴이있는 이미지를 제공하면 적절한 수의 관측치를 얻게됩니다.
 관찰의 또 다른 중요한 특성은 관찰이 불변하다는 것이다.
 사용 된 예제를 살펴 보겠습니다.
 내가주의를 기울이기를 바라는 두 가지 속성이 있으며, 그들은 모두 관측을 위해 기초에서 [안 들림]으로 선언됩니다.
 하나는 고유 한 ID입니다.
 이 고유 ID는이 특정 결과에 대한 처리 단계를 식별합니다.
 또 하나는 신뢰 수준입니다.
 신뢰 수준은 알고리즘이 결과를 산출하는 자신감을 나타냅니다.
 신뢰도는 0에서 1 사이입니다.
 이 주제에 대해서도 다음 세션에서 더 자세히 다룰 예정입니다.
 요청 파이프 라인을 살펴 보겠습니다.
 파이프 라인이란 무엇입니까? 세 가지 요청이 있다고 가정 해 봅시다. 요청 # 1은 요청 # 2의 실행에 의존하며, 요청 # 2는 요청 # 3의 실행에 따라 달라집니다.
 처리가 반대 순서로 진행되는 동안 시퀀스를 어떻게 처리합니까? 여기서 제가하려고하는 것은, 우선, 제 요청 # 3을 처리 할 것입니다.
 요청에서 결과를 얻고 요청 # 2에 피드를 제공 할 것입니다.
 요청 # 2와 정확히 똑같이 할 것입니다.

마지막으로 요청 # 1을 처리합니다.
 요청 파이프 라인을 암시 적 및 명시 적 순서로 실행하는 방법의 예를 살펴 보겠습니다.
 이 두 가지 사용 사례에서 다음 두 슬라이드를 살펴보고 얼굴 표식 감지기를 실행합니다.
 아시다시피, 랜드 마크, 얼굴 표식은 얼굴의 특징입니다.
 그것은 당신의 얼굴에 눈, 눈썹, 코, 입 위치입니다.
 먼저 암묵적으로 수행하는 방법을 살펴 보겠습니다.
 나는 우리가 이미 보았던 것과 조금 비슷한 간단한 [들리지 않음]을가집니다.
 먼저, 얼굴 표식 요청을 작성하겠습니다.
 그런 다음 이미지 요청 처리기를 만들겠습니다.
 그런 다음 요청을 처리 할 것입니다.
 그리고 마지막으로 결과를 살펴 보겠습니다.
 그 안에 하나의 얼굴이있는 이미지가 있으면 내 결과는 다음과 같을 것입니다.
 죄송합니다.
 N은 시퀀스와 결과를 나타냅니다.
 그래서 저는 얼굴의 테두리 상자를 얻습니다.
 그것이 얼굴의 위치이며, 나는 얼굴을위한 표식을 얻습니다.
 여기서 주목해야 할 중요한 점은 얼굴 표식 요청 처리가 시작될 때 얼굴 표식 요청이 아직 얼굴을 감지하지 못했음을 알려주고 얼굴 탐지기 내부에서 실행된다는 것입니다.
 그것은 그 얼굴 탐지기에서 결과를 얻습니다. 그리고 그것은 표식이 검색되는 곳입니다.
 오른쪽에는 얼굴 관측 대상이 어떻게 생겼는지를 보여주는 조각을 볼 수 있습니다.
 이것들은 그 객체의 몇개의 필드입니다.
 하나는 고유 한 번호로 설정 한 고유 한 ID입니다.
 그런 다음 경계 상자, 즉 얼굴이있는 곳, 그리고 마지막으로 랜드 마크 필드가 있습니다. 랜드 마크 필드는 랜드 마크가 설명 된 일부 객체를 가리 킵니다.
 이제 같은 사용 사례를 살펴 보겠습니다.하지만 이제는 명시 적으로 수행됩니다.
 먼저 여기에서해야 할 일은 - 먼저 얼굴 탐지기를 명시 적으로 실행합니다.
 프레젠테이션에서이 네 줄의 코드를 여러 번 본 적이 있습니다.
 내가 그것을 실행할 때, 나는 테두리 박스를 되 찾는다.
 보시다시피 결과는 얼굴 유형과 동일한 유형으로 반환됩니다.
 이전 슬라이드에서 본 필드는 이와 같이 보일 수 있으므로 특정 처리 단계를 식별 할 수있는 고유 한 번호가 표시됩니다.
 그런 다음이 요청을 처리하는 주요 결과 인 테두리 상자 위치를 가져옵니다.
 그리고 얼굴 검출기는 랜드 마크에 대해 아무것도 모르기 때문에 랜드 마크 필드는 nil로 설정됩니다.
 다음으로 할 일은 랜드 마크 요청을 작성한 다음 이전 단계의 결과를 가져 와서 해당 요청의 입력 개체 관찰 속성에 입력하는 것입니다.
 그런 다음 요청 처리기에 처리하도록 요청할 것입니다.
 그리고 마지막으로 결과를 살펴 보겠습니다.
 같은 이미지에서 실행하면 이전 슬라이드와 똑같은 결과를 얻게됩니다.
 그러나 관측으로 어떤 일이 일어나는지 보자.
 얼굴 검출기와 얼굴 표식 검출기가 모두 동일한 유형을 반환하지만 관측치가 불변이지만 우리는 주입 된 관측치를 무시하지 않는다고 말했습니다.
 대신에 처음 두 필드를 가져 와서 새 객체로 복사 한 다음 랜드 마크를 계산하고 랜드 마크 필드를 채 웁니다.
 자, 이제 보면, 대부분의 경우 UID가 동일하다는 것을 알게 될 것입니다.
 왜 그런가요? 왜냐하면 우리는 같은 얼굴에 대해 이야기하기 때문입니다.
 원한다면 같은 처리 단계입니다.
 당신은 암시 적 대 명시 적을 어디에서 사용하겠습니까? 글쎄, 만약 당신의 어플리케이션이 매우 단순하다면, 당신은 아마 암시적인 방법을 선택하고 싶을 것이다.
 매우 간단합니다.
 단일 요청을 만듭니다. 그 밖의 모든 일은 당신을 대신해서 이루어집니다.
 반면에 응용 프로그램이 더 복잡한 경우 (예 : 얼굴을 먼저 처리하고 감지 한 다음 필터링을 수행하려는 경우).
 주변에있는 얼굴에 관심이 없거나 가운데에있는 얼굴에만 집중하고 싶으면 그 단계를 수행 한 다음 나머지 얼굴 세트에 랜드 마크를 적용 할 수 있습니다.
 이 경우 명시적인 버전을 사용하고 싶을 것입니다.이 경우 랜드 마크 감지기가 안면 감지기를 다시 실행하지 않기 때문입니다.
 우리는 귀하의 애플 리케이션이 메모리 사용 및 실행 속도면에서 모두 최적의 성능을 발휘하기를 바랍니다.
 그렇기 때문에 다음 두 장의 슬라이드를 보는 것이 중요합니다.
 얼마나 오래 물건을 기억해야합니까? 음, 이미지 요청 처리기의 경우 이미지 처리가 필요한 동안에는 계속 처리해야합니다.
 이것은 매우 순진하고 단순한 진술처럼 들리지만, 당신이 그렇게하는 것이 매우 중요합니다.
 개체를 일찍 릴리스하고 아직 해결되지 않은 처리 요청이있는 경우 처리기를 요청하기 위해 이미지를 다시 만들어야합니다.
 그러나 이제는 이전 객체와 관련된 모든 캐시를 잃어 버렸으므로 이러한 파생물을 다시 계산하려면이 성능을 지불해야합니다.
 너무 늦게 릴리스하면 다른 한편으로는 먼저 메모리 조각화를 일으키기 시작합니다. 그러면 메모리가 앱에서 원하는 의미있는 일을하도록 회수되지 않습니다.

따라서 릴리스하고, 필요에 따라 사용하고, 바로 해제하는 것이 중요합니다.
 이미지와 여러 이미지 파생물을 내부에 캐시합니다.
 시퀀스 요청 처리기가있는 상황은 매우 비슷합니다. 유일한 차이점은 너무 일찍 릴리스하면 캐시 전체가 사라져서 전체 시퀀스를 거의 종료한다는 것입니다.
 요청과 관찰은 어떻습니까? 요청과 관찰은 매우 가벼운 객체입니다.
 필요에 따라 생성하여 릴리스 할 수 있습니다.
 캐시 할 필요가 없습니다.
 우리는 귀하의 요청을 어디에 처리해야합니까? Vision의 많은 요청은 장치에서 신경망을 실행하는 데 의존합니다.
 그리고 우리가 알고 있듯이, 신경망을 운영하는 것은 CPU 대 GPU에서 더 빠릅니다.
 그래서 자연스러운 질문은 어디에서 실행해야 하는가입니다. 비전에서 우리가하는 일은 다음과 같습니다.
 요청이 GPU에서 실행 가능한 경우 먼저 시도합니다.
 그 시점에서 GPU를 사용할 수없는 경우 CPU가 기본 동작이므로 CPU로 전환합니다.
 그러나 응용 프로그램이 화면에 많은 그래픽을 표시하는 것에 의존한다고 가정 해 보겠습니다. 그러면 특정 작업에 대한 GPU를 저장할 수 있습니다.
 이 경우 속성에서 사용자 CPU를 무시하고 요청 개체에서 true로 설정할 수 있습니다.
 이렇게하면 CPU에서 직접 요청을 처리 할 수 ​​있습니다.
 이제 Vision, Vision API와 상호 작용하는 기본적인 방법에 대해 살펴 보았습니다. 두 가지 예를 살펴 보았습니다. Vision에서 추적중인 프레젠테이션의 주요 주제로 전환 해 봅시다.
 추적이란 무엇입니까? 추적은 일련의 프레임에서 관심 객체를 찾는 문제로 정의됩니다.
 일반적으로 첫 번째 프레임에서 해당 오브젝트를 찾고 프레임 순서로 찾으려고합니다.
 그러한 신청의 예는 무엇입니까? 당신은 아마 그들 중 많은 것을 보게 될 것입니다.
 그것은 라이브 annotational 스포츠 이벤트, 카메라, 많은, 많은 다른 사람과 추적 추적.
 시퀀스의 모든 프레임에서 탐지를 수행 할 수 있다면 왜 추적을 사용해야한다고 말할 수 있습니까? 음, 여러 가지 이유가 있습니다.
 먼저, 추적하려는 모든 유형의 개체에 대한 특정 추적기가 없을 것입니다.
 얼굴을 추적하는 경우 운이 좋다고 해봅시다.
 그 목적을 위해 얼굴 검출기가 있습니다.
 그러나 예를 들어 특정 유형의 새를 추적해야하는 경우에는 해당 탐지기가없는 것일 수 있습니다. 이제는 특정 탐지기를 만들 수 있습니다. 다른 탐지기로 인해 원하지 않을 수도 있습니다. 응용 프로그램을 사용하여 수행하려는 작업
 하지만 당신이 운이 좋다면 탐지기를 사용해야 만 얼굴을 추적한다고 가정 해 봅시다. 글쎄, 아마도이 사건 중 하나.
 이제 예제를 살펴 보겠습니다.
 추적 시퀀스를 시작하고 첫 번째 프레임에서 얼굴 검출기를 실행합니다.
 다섯 얼굴을 되 찾는다.
 그런 다음 두 번째 프레임에서 실행합니다. 또 다른 다섯 얼굴을 되 찾는다.
 두 번째 프레임의 얼굴이 첫 번째 프레임의 얼굴과 정확히 같은 것을 어떻게 알 수 있습니까? 한 사람이 빠져 나올 수있었습니다. 다른 하나가 나타났다.
 이제는 발견 한 객체와 일치하는 작업을 수행하고 있습니다.이 작업은 처리하고 싶지 않을 수있는 완전히 다른 작업입니다.
 반면 추적자는 [들리지 않는] 정보를 사용하여 객체를 일치시킵니다.
 그들은 물체가 어떻게 움직이는 지에 대한 궤적을 알고 있으며, 다음 프레임에서 움직이는 위치를 약간 예측할 수 있습니다.
 하지만 다시 운이 좋다 면요.
 얼굴을 추적하고 있으며 유스 케이스는 프레임의 한면으로 제한됩니다.
 그러면 감지기를 사용해야합니까? 음, 아마도이 경우조차도.
 이제 속도가 문제입니다.
 추적기는 일반적으로 경량 알고리즘이지만 탐지기는 대개 [들리지 않음]을 실행하므로 훨씬 길어집니다.
 또한 그래픽 사용자 인터페이스에 추적 정보를 표시해야하는 경우 추적기가 더 부드럽고 불안정하지 않을 수도 있습니다.
 첫 번째 슬라이드 중 하나에서이 세 가지 용어, 내용, 방법 및 결과를 기억해달라고 요청했습니다.
 이것이 트랙과 유스 케이스에 어떻게 매핑되는지 살펴 보겠습니다.
 먼저 요청하십시오.
 따라서 Vision에는 두 가지 유형의 추적 요청이 있습니다.
 일반적인 목적의 물체 추적기가 있으며 사각 물체 추적기가 있습니다.
 방법? 지금까지 짐작 했겠지만, 우리는 시퀀스 요청 핸들러를 사용할 것입니다.
 결과.
 여기서 중요한 두 가지 유형이 있습니다.
 탐지 된 객체 관찰에는 중요한 속성이 있습니다. 경계 상자는 객체의 위치를 ​​알려주고 사각형 관찰은 사각형의 정점 위치를 알려주는 4 개의 추가 속성을 가지고 있습니다.
 이제 경계 상자가 있으면 사각형의 정점이 필요한 이유는 무엇입니까? 글쎄, 당신이 직사각형을 그릴 때, 그들은 실생활에서 직사각형의 물건입니다.
 그들이 프레임에 투영되는 방식은 다르게 보일 수 있습니다.
 예를 들어 사다리꼴처럼 보일 수 있습니다.
 따라서이 경우 경계 상자는 사각형 자체가 아닙니다.

사각형의 모든 꼭지점을 포함하는 최소 상자.
 이제 데모를 살펴 봅시다.
 그래서, 제가 여기있는 것은, 당신이 WWDC 웹 사이트에서 다운로드 할 수있는 샘플 응용 프로그램을 가지고 있으며이 세션 바로 옆에 링크가 있습니다.
 앱이하는 일은 영화를 찍는 것입니다. 그 영화를 프레임으로 구문 분석합니다.
 첫 번째 프레임에서는 객체를 선택합니다.
 여러 개체를 추적하려고하거나 추적하려는 경우 추적을 수행합니다.
 먼저이 영화를 사용합시다.
 사용자 인터페이스는 간단합니다.
 먼저, 객체 또는 사각형 중에서 선택할 수 있고, 둘째, 빠르고 정확하게 사용할 알고리즘을 선택할 수 있습니다.
 비전에서 우리는 빠르고 정확하게 두 가지 유형을 지원하며 이는 속도와 정확성 간의 균형입니다.
 이 경우 객체를 표시 할 것이고, 빠른 알고리즘을 사용할 것입니다.
 객체를 선택합시다.
 그래서 저는이 사람을 빨간 우산 아래에서 추적 할 것입니다. 그리고 나는이 사람들의 집단을 여기에서 추적하려고 노력할 것입니다.
 뛰자.
 보시다시피, 우리는 우리가 선택한 대상을 성공적으로 추적 할 수 있습니다.
 보다 복잡한 예제를 살펴 보겠습니다.
 여기에서 추적하고 싶은 것은,이 wakeboarder 사람을 추적하고 싶습니다.이 경우 정확한 알고리즘을 사용하려고합니다.
 그래서, 저는 객체를 선택하려고합니다. 그리고 저는 그것을 실행할 것입니다.
 보시다시피,이 객체는 그 자체, 모양, 위치, 색상, 모든 것에 대해 거의 모든 것을 변경합니다.
 우리는 여전히 그것을 추적 할 수 있습니다.
 나는 이것이 꽤 멋지다 고 생각한다.
 이제 데모 머신으로 전환하고 실제 추적 시퀀스가이 앱에서 어떻게 구현되는지 살펴 보겠습니다.
 따라서 Xcode를 실행하고 헤드폰을 연결하면 방금 보았던 것과 동일한 응용 프로그램이 실행됩니다.
 디버거에서 실행하고, 내 객체를 선택하며, 시퀀스를보고 싶기 때문에 내가 선택한 것을 중요하지 않습니다.
 그리고 나는 그것을 실행할 것입니다.
 그래서, 여기에 브레이크 포인트를 설정하고 그것은이 응용 프로그램의 가장 중요한 기능입니다 수행 추적 기능에서 휴식.
 이것이 실제 시퀀스를 구현하는 함수입니다.
 우리가 여기서 무엇을하는지 봅시다.
 첫째, 우리는 비디오 리더를 만들고 있습니다.
 그런 다음 첫 번째 프레임을 읽는 중입니다. 프레임을 객체를 선택하는 데 사용했기 때문에 해당 프레임을 폐기합니다.
 여기에 취소 깃발이 있습니다.
 그런 다음, 입력 한 관측치의 수집을 초기화 할 것입니다.
 슬라이드에서 예제를 보았던 것을 기억하십시오.
 그런 다음 trackenPolyRect 유형으로 유지되는 그래픽 사용자 인터페이스에서 결과를 표시 할 수 있도록 부기를 보관합니다.
 그런 다음 유형에 스위치를 실행하려고합니다. 유형은 사용자 인터페이스에서 가져온 것으로,이 경우에는 객체로 작업합니다.
 이제 두 개의 객체를 선택했습니다.
 따라서 이것은 사용자 인터페이스에서 오는 정보입니다.
 우리는이 두 가지 목적을 여기에서보아야합니다.
 좋아요, 그 중 두 가지가 있습니다.
 따라서이 루프는 두 번 실행됩니다.
 그것은 입력 관측을 초기화 할 것입니다.
 경계 상자를 전달하여 슬라이드에 표시된 것과 같이 감지 된 객체 관찰을 생성합니다.
 그리고 우리는 부기 구조를 초기화합니다.
 뛰자.
 관측 대상을 살펴 봅시다.
 여기서 중요한 몇 가지 필드가 있습니다.
 이것은 우리가 논의한 고유 한 ID입니다.
 그리고 정규화 조직의 경계 상자입니다.
 자, 이제 끝내면이 중단 점을 맞힐 것입니다.이 경우 우리는 [들리지 않는] 직사각형을 사용하지 않기 때문입니다.
 여기에서 시퀀스 요청 처리기를 만듭니다.
 자, 프레임 카운터가 있습니다. 뭔가 실패하면 깃발을 들고 마침내 추적 시퀀스를 시작하겠습니다.
 보시다시피 이것은 무한 루프이며 취소가 요청되거나 동영상이 종료 된 경우 루프를 빠져 나갈 수있는 조건이 있습니다.
 이 인터페이스의 그래픽 사용자를위한 정보를 나중에 표시하도록 rect 구조를 초기화하고 입력 관측을 반복 할 것입니다.
 각각에 대해 트랙 객체 요청을 생성 할 것입니다.
 모든 요청 수집에 대한 요청을 진행할 예정이며,이 경우에해야합니다.
 루프를 끝내고 마지막으로 요청을 처리 할 준비가되었습니다.
 이제 수행 된 요청을 볼 수있는 경우 perform 함수는 요청 모음을 허용합니다.
 슬라이드에서는 단일 요청 만 해당 컬렉션으로 전달되었지만 여기에서는 두 개의 요청을 동시에 추적합니다.
 나는 그것을 수행 할 것이다.
 이제 요청이 수행 된 이후로 결과를 살펴보기 시작하고 각 결과 속성을 살펴보고이를 수행 할 것입니다.
 그래서 결과 속성을 얻으려고합니다.
 저는 그 속성에서 첫 번째 객체를 얻을 것입니다. 왜냐하면 우리는 그것들을 하나의 관찰로 기대하기 때문입니다.
 여기서 내가 할 일은 관찰의 신뢰 속성을 살펴보고 임의의 임계 값을 0.5로 설정합니다.

임계 값보다 높으면 테두리 상자를 실선으로 그릴 것입니다. 임계 값보다 낮 으면 파선으로 그릴 것입니다.
 그래서, 제가 가지고있는 일이 잘못되어 가고 있다는 것을 나타낼 수 있습니다.
 나머지는 간단한 부기입니다.
 저는 rect 구조체를 채울 것입니다. 이것은 마지막 단계입니다. 현재 반복에서 관측치를 얻는 것이 매우 중요하며, 다음 반복을 위해 할당합니다.
 나는 그것을 두 번 할 것입니다.
 나는이 중단 점에 도달 할 것이다.
 내 프레임을 표시하려고합니다.
 나는 실제 영화를 시뮬레이트하기 위해 초 단위로 프레임 속도를 기다릴 것이다.
 그리고, 당신이 그것을 알기도 전에, 당신은 당신의 추적 순서의 두 번째 반복에 있습니다.
 이제 슬라이드로 돌아가 봅시다.
 고맙습니다.
 자, 방금 본 것을 기억하는 것이 중요합니다.
 먼저 추적을 위해 초기 객체를 초기화하는 방법과 두 가지 방법을 살펴 보았습니다.
 일반적으로 특정 탐지기를 실행하고 바운딩 박스를 꺼내서 자동으로 수행됩니다.
 두 번째는 일반적으로 사용자 입력에서 오는 수동입니다.
 또한 추적 된 개체 당 하나의 추적 요청을 사용함을 알았습니다.
 여기의 관계는 일대일입니다.
 우리는 또한 두 가지 유형의 추적 장치가 있음을 확인했습니다.
 하나는 범용 트래커이고 다른 하나는 직사각형 오브젝트 트래커입니다.
 우리는 또한 각 추적기 유형에 대해 두 가지 알고리즘이 있음을 알게되었습니다.
 빠르고 정확하며 속도와 정확도 사이의 균형을 나타냅니다.
 마지막으로, 우리는 신뢰 수준 속성을 사용하여 결과를 신뢰할 것인지 여부를 판단하는 방법을 살펴 보았습니다.
 Vision에서 추적 시퀀스를 구현하는 데는 어떤 한계가 있습니까? 먼저, 추적자의 수에 대해 이야기 해 봅시다.
 얼마나 많은 물체를 동시에 추적 할 수 있습니까? Vision에는 각 유형별로 16 개의 추적자가 설정되어 있습니다.
 따라서 16 개의 범용 오브젝트 추적기와 16 개의 직사각형 오브젝트 추적기를 가질 수 있습니다.
 더 할당하려고하면 오류가 발생합니다.
 그래서, 만약 당신이 이미 당신이 이미 사용하고있는 추적기의 일부를 공개해야합니다.
 그렇게하는 방법? 첫 번째 방법은 요청에서 마지막 프레임 속성을 설정하고 해당 요청을 처리하기 위해 요청 처리기에 제공하는 것입니다.
 그런 식으로 요청 처리기는이 요청 개체와 관련된 추적기가 해제되어야 함을 알게됩니다.
 또 다른 방법은 전체 시퀀스 요청 핸들러를 해제하는 것입니다. 이 경우 해당 요청 핸들러와 연관된 모든 추적기가 해제됩니다.
 이제 추적 신호를 구현했다고 가정 해 보겠습니다.
 당신이 직면하게 될 잠재적 인 도전은 무엇입니까? 여러분이 보았 듯이 추적 순서의 객체는 거의 모든 것을 스스로 변경할 수 있습니다.
 그것들은 모양, 외양, 색깔, 위치를 바꿀 수 있으며 알고리즘에 대한 큰 도전이됩니다.
 그럼 여기서 뭘 할 수 있니? 음, 한 가지 불행한 대답은 여기에 모든 해결책을 제시 할 수있는 크기가 없다는 것입니다.하지만 몇 가지 시도해 볼 수 있습니다.
 첫째, 빠르고 정확하게 플레이 할 수 있으며 특정 알고리즘을 사용하여 특정 유스 케이스가 더 잘 작동한다는 것을 알 수 있습니다.
 경계 상자를 선택하는 작업을 담당하는 경우 동일한 돌출 오브젝트를 찾아보십시오.
 사용할 신뢰도 임계 값은 무엇입니까? 다시 말하지만 여기에 하나의 대답은 없습니다.
 일부 유스 케이스는 특정 임계 값에서 작동하는 반면 다른 유스 케이스는 다른 임계 값과 함께 작동한다는 것을 알 수 있습니다.
 내가 추천 할 수있는 또 하나의 기법이있다.
 추적 시퀀스가 ​​길고이 예에서는 1,000 프레임이라고 가정 해 보겠습니다.
 추적 시퀀스를 시작하면 첫 번째 프레임에서 선택한 객체가 이탈하기 시작하고 초기 프레임에서 벗어날수록 그 자체에 대한 모든 사항이 변경됩니다.
 대신에 할 수있는 일, 그 시퀀스를 더 작은 하위 시퀀스로 나눌 수 있습니다. 각각 50 프레임을 가정 해 봅시다.
 탐지기를 실행하면 50 개의 프레임을 추적 할 수 있습니다.
 감지기를 다시 실행하십시오. 당신은 50 프레임 동안 다시 실행하고, 당신은 그렇게 계속합니다.
 최종 사용자의 관점에서 볼 때 단일 객체를 추적하는 것처럼 보입니다.
 그러나 대신 당신이하는 일, 대신에 내부에서 수행하는 작업, 더 작은 시퀀스를 추적하는 것이 시퀀스를 실행하고 추적하는 더 똑똑한 방법입니다.
 우리가 오늘 본 것을 요약 해 봅시다.
 먼저 Vision을 사용해야하는 이유에 대해 이야기하고 간단하고 일관된 인터페이스를 제공하는 개인 정보 중심의 다중 플랫폼 프레임 워크에 대해 이야기했습니다.
 둘째, 우리는 새로운 것에 대해 이야기했고, 새로운 오리엔테이션에 의존하지 않는 얼굴 검출기를 소개했습니다.
 우리는 개정에 대해서도 이야기했습니다.
 그런 다음 Vision API와 상호 작용하는 방법에 대해 이야기하고 요청, 처리기 및 관찰을 논의했습니다.
 마지막으로 Vision에서 추적 시퀀스를 구현하는 방법을 살펴 보았습니다.
 자세한 내용은 슬라이드의이 링크를 참조하는 것이 좋습니다.

다음 세션을 위해 머물도록 권할 수도 있습니다. Frank는 Vision과 CoreML의 통합에 대한 자세한 내용을 담고있는이 방에서 3시에있을 것입니다.
  자신의 모델을 배포하려는 경우 특히 중요합니다.
  이 세션에서는이 세션에서 다루지 않은 Vision Framework에 대한 세부 정보도 다룹니다.
  그리고 우리는 내일 3 월 5 일 Vison Lab을 가질 것입니다.
  고맙습니다. WWDC의 훌륭한 휴식을 누려보십시오.
