좋은 아침.
 환영.
 저는 Michael입니다.이 세션에서는 Core ML의 새로운 기능에 대해 설명합니다.
 1 년 전에 소개 된 Core ML은 기계 학습 모델을 앱에 통합하는 것이 믿을 수 없을만큼 간단하도록 만드는 것입니다.
 지난 한 해 동안 채택 된 것을 보아서 정말 기뻤습니다.
 앱에서 이미지의 내용을 이해하거나 텍스트를 분석 할 수있는 기능을 제공한다면 어떤 새로운 멋진 경험을 할 수 있는지 생각 해보길 바랍니다.
 앱이 오디오 또는 음악에 대해 추론 할 수 있거나 모션 동작을 기반으로 사용자의 동작을 해석하거나 새로운 콘텐츠를 변형 또는 생성 할 수 있다면 무엇을 할 수 있습니까? 이 모든 것, 그리고 훨씬 더 많은 것이 쉽게 도달 할 수 있습니다.
 이러한 유형의 기능이 Core ML 모델에서 인코딩 될 수 있기 때문입니다.
 이제 이들 중 하나를 들여다 보면 신경망, 나무 앙상블 또는 다른 모델 아키텍처를 발견 할 수 있습니다.
 수백만 개의 매개 변수가있을 수 있으며 그 값은 많은 양의 데이터로부터 배웠습니다.
 그러나 당신을 위해, 당신은 하나의 파일에 집중할 수 있습니다.
 구현 세부 사항보다는 제공하는 기능과 경험을 중점적으로 다룰 수 있습니다.
 앱에 코어 ML 모델을 추가하는 것은 Xcode 프로젝트에 해당 파일을 추가하는 것만 큼 간단합니다.
 Xcode는 간단한보기를 제공하고 필요한 입력과 출력에서 ​​제공하는 내용을 설명합니다.
 Xcode는 한 단계 더 나아가서 인터페이스를 생성하므로이 모델과의 상호 작용은 모델을로드하는 코드, 예측을 수행하는 모델, 특정 출력을 끌어내는 코드의 몇 줄에 불과합니다. 관심이있다.
 코어 ML은 일부 상위 API와 통합되므로 코어 ML 모델을 제공 할 경우 행동을 사용자 정의 할 수 있기 때문에 코드를 다시 작성하지 않아도되는 경우도 있습니다.
 따라서 Vision에서는 VNCoreML Request 개체를 통해이 작업을 수행합니다.
 새로운 Natural Language 프레임 워크에서는 CoreML 모델에서 MLModel을 인스턴스화 할 수 있습니다.
 요컨대 Core ML입니다.
 그러나 우리는 새로운 것에 대해 이야기하기 위해 왔습니다.
 우리는 지난 한 해 동안 귀하로부터받은 위대한 의견을 모두 수령하여 CoreML 2에 대한 주요 개선 사항에 중점을 두었습니다.
 그리고 우리는 두 세션에서 이것들에 대해서 이야기 할 것입니다.
 첫 번째 세션에서 여러분이 지금 앉아있는 세션에서 우리는 앱의 관점에서 새로운 것에 대해 이야기 할 것입니다.
 두 번째 세션에서는이 직후 10시에 시작됩니다.
엠.
 짧은 휴식 시간 후에 우리는 도구에 대해 이야기하고 모델을 업데이트하고 변환하여 Core ML 2의 새로운 기능을 활용하는 방법에 대해 이야기 할 것입니다.
 앱에 관해서는 세 가지 핵심 영역에 집중할 것입니다.
 첫 번째 방법은 동일한 기능을 사용하면서 앱을 사용하여 모델의 크기와 수를 줄이는 방법입니다.
 그런 다음 단일 모델에서 더 많은 실적을 얻을 수있는 방법을 살펴 보겠습니다.
 그리고 Core ML을 사용하여 어떻게 최첨단의 빠르게 움직이는 기계 학습 분야에 보조를 맞출 수 있는지에 대해 결론을 맺을 것입니다.
 그래서 그것을 걷어차 기 위해 모델 크기에 대해 이야기 해 봅시다.
 나는 그것을 Francesco에게 건네 주겠다.
  마이클 고마워.
 여보세요.
 핵심 ML 응용 프로그램의 크기를 줄이는 모든 방법은 매우 중요합니다.
 내 이름은 Francesco이고, 응용 프로그램 크기를 줄이는 데 도움이되는 Core ML 2의 두 가지 새로운 기능인 양자화 및 유연한 모양을 소개하려고합니다.
 그래서 코어 ML, [안 들려] 왜 모델과 장치에서 배워야 만합니다.
 이렇게하면 클라우드에서 실행하는 것과 비교하여 앱에 4 가지 주요 이점이 있습니다.
 우선, 사용자의 개인 정보는 완전히 존중됩니다.
 장치에 많은 기계 학습 모델이 있습니다.
 우리는 데이터가 사용자의 장치를 벗어나지 않도록 보장합니다.
 둘째, 실시간 성능을 달성하는 데 도움이됩니다.
 실리콘의 경우 음성 및 장치가 기계 학습 작업 부하에 매우 효율적입니다.
 또한 인터넷 서버를 유지 보수 할 필요가 없습니다.
 코어 ML 추론은 자연스러운 연결 문제에도 불구하고 언제 어디에서나 사용할 수 있습니다.

이러한 모든 이점은 이제 기기 학습 모델을 기기에 저장해야한다는 점에서 중요합니다.
 그리고 기계 학습 모델이 크다면 앱의 크기가 걱정 될 수도 있습니다.
 예를 들어, 당신은 당신의 [들리지 않음]지도를 가지고 있으며 멋진 기능들이 가득합니다.
 그리고 사용자는 매우 만족합니다.
 이제는 기기에서 학습하는 기기에서 제공하는 새로운 기회를 활용하고 앱에 새로운 놀라운 기능을 추가하려고합니다.
 그래서 당신이 할 일은 몇 가지 핵심 ML 모델을 훈련시키고이를 당신의 앱에 추가하는 것입니다.
 이것이 의미하는 바는 앱이 더욱 멋지고 사용자가 더 행복하다는 것입니다.
 그러나 그들 중 일부는 앱의 크기가 약간 증가한 것을 알 수 있습니다.
 앱이 기계 학습 기능을 추가 한 후 수십 메가 바이트 또는 수백 메가 바이트로 성장하는 것을 보는 것은 드문 일이 아닙니다.
 또한 앱에 계속해서 더 많은 기능을 추가하면 앱의 크기가 제어 불능 상태가 될 수도 있습니다.
 이것이 당신이 할 수있는 첫 번째 일입니다.
 또한 이러한 기계 학습 모델이 앱의 다른 기능을 지원하는 경우 초기 번들 외부에 유지할 수 있습니다.
 그런 다음 사용자가 다른 기능을 사용하면 필요에 따라 다운로드하고 장치에서 컴파일 할 수 있습니다.
 따라서이 경우 설치 크기가 변경되지 않으므로이 사용자는 처음에는 만족 스럽습니다.
 그러나 사용자가 앱의 모든 현재 Core ML 기능을 다운로드하여 사용하기 때문에 하루가 끝날 때 앱의 크기는 여전히 커집니다.
 대신 모델 자체의 크기를 줄임으로써이 문제를 해결할 수 있다면 더 좋지 않을까요? 이렇게하면 우리가 다운로드 한 앱에서 모델을 선적하는 대신에 더 빠르고 더 작은 다운로드를 통해 앱 내부에 모델을 출시 할 수있는 작은 묶음이 생깁니다.
 그리고 어쨌든 앱은 더 적은 메모리를 차지합니다.
 메모리 사용량을 줄이면 앱 성능이 향상되고 일반적으로 시스템 성능이 향상됩니다.
 그렇다면이 문제를 해결하기 위해 핵심 ML 앱의 크기를 요인으로 분해 할 수있는 방법을 살펴 보겠습니다.
 첫째, 모델 수가 많습니다.
 이것은 앱에 몇 가지 기계 학습 기능이 있는지에 달려 있습니다.
 다음 가중치가 있습니다.
 가중치의 수는 기계 학습 문제를 해결하기 위해 선택한 아키텍처에 따라 다릅니다.
 Michael이 언급 한 바와 같이, 가중치의 수 - 가중치는 기계 학습 모델이 교육 중에 학습 한 정보를 저장하는 장소입니다.
 따라서 복잡한 작업을 수행하도록 훈련받은 경우 수천만 개의 가중치가 필요한 모델을 보는 것이 일반적입니다.
 마지막으로, 체중의 크기가 있습니다.
 교육 과정에서 배우는 매개 변수를 어떻게 저장합니까? 먼저이 요소에 초점을 맞추자.
 신경망의 경우, 우리는 가중치를 표현하고 저장할 수있는 몇 가지 옵션이 있습니다.
 첫 번째는 iOS 11의 Core ML입니다.
 신경망은 부동 소수점 32 비트 가중치를 사용하여 저장되었습니다.
 iOS 11에서.
2, 우리는 여러분의 의견을 듣고 우리는 반 정밀도 부동 소수점 16의 가중치를 도입했습니다.
 이렇게하면 앱이 동일한 정확도로 필요한 저장 공간의 절반을 차지합니다.
 그러나 올해 우리는 몇 단계 더 나아가고 싶었고, 우리는 양자화 된 가중치를 도입하고 있습니다.
 양자화 된 가중치를 사용하면 더 이상 Float 32 또는 Float 16 값을 사용하도록 제한되지 않습니다.
 그러나 신경망은 8 비트, 4 비트, 모든 비트를 1 비트까지 사용하여 인코딩 할 수 있습니다.
 여기에 양자화가 무엇인지 보도록하겠습니다.
 여기서 우리는 신경망의 가중치의 부분 집합을 나타냅니다.
 보시다시피 이러한 가중치는 연속 범위에서 어떤 값을 가질 수 있습니다.
 이것은 이론적으로 단일 가중치가 무한한 수의 가능한 값을 취할 수 있음을 의미합니다.
 그래서 실제로, 신경 네트워크에서 우리는 32 점 부동 소수점 수를 사용하여 가중치를 저장합니다.
 즉,이 가중치는 연속 된 특성을 더 잘 표현하기 위해 수십억 개의 값을 가질 수 있습니다.
 그러나 신경 네트워크가 더 낮은 정밀도의 무게로도 작동한다는 것이 밝혀졌습니다.
 양자화는 값의 문자열을 중단하는 데 필요한 프로세스이며 가능한 값의 매우 작고 이산적인 하위 집합을 사용하도록 제한합니다.
 예를 들어, 여기서 양자화는이 가중치의 연속 스펙트럼을 단지 256 개의 가능한 값으로 바꾸었습니다.
 따라서 양자화 전에 가중치는 가능한 모든 값을 취합니다.
 양자화 후에는 256 가지 옵션 만 있습니다.
 이제이 작은 세트에서 그 무게를 가져올 수 있기 때문에 코어 ML은 이제 8 비트의 저장된 정보 만 필요합니다.
 그러나 아무것도 우리를 여기에서 멈출 수 없다.
 우리는 더 나아갈 수 있습니다.
 예를 들어, 우리는 56 개의 다른 값 중 하나 (예 : 8 개) 대신 네트워크를 제한 할 수 있습니다.
 그리고 이제는 8 가지 옵션 만 제공하기 때문에 Core ML은 모델을 저장하기 위해 무게 당 3 비트 값이 필요합니다.
 이제는 가중치를 나타 내기 위해이 값을 선택하는 방법에 대한 세부 정보가 있습니다.

그것들은이 범위에서 균일하게 분포 될 수 있으며,이 경우 우리는 룩업 테이블 양자화 대신에 선형 양자화를 가지며,이 값들을 임의의 방식으로이 범위에 분산시킬 수 있습니다.
 그럼 실제로 양자화가 우리 모델의 크기를 줄이는 데 어떻게 도움이되는지 봅시다.
 이 예에서는 다양한 응용 프로그램에서 여러 가지 작업을 수행하는 데 사용되는 일반적인 아키텍처 인 Resnet50에 중점을 둡니다.
 2 천 5 백만 개의 훈련 된 매개 변수가 포함되어 있으므로이를 표현하기 위해 32 비트 부동 소수점을 사용해야합니다.
 그런 다음 총 모델 크기는 100 메가 바이트 이상입니다.
 8 비트로 양자화하면 아키텍처가 변경되지 않았습니다. 우리는 여전히 2 천 5 백만개의 매개 변수를 가지고 있습니다.
 그러나 이제는 단일 가중치를 저장하기 위해 1 바이트 만 사용하고 있으며, 이는 모델 크기가 4 배로 줄어든다는 것을 의미합니다.
 단지이 모델을 저장하는 데 26 메가 바이트 밖에 걸리지 않습니다.
 그리고 우리는 더 나아갈 수 있습니다.
 이 모델에서는 가중치 당 4 비트 만 사용하고 더 작은 모델로 끝나는 양자화 된 표현을 사용할 수 있습니다.
 Core ML은 모든 양자화 모드를 8 비트까지 지원합니다.
 이제 양자화는 기존 아키텍처와 그보다 작은 버전을 사용하는 강력한 기술입니다.
 그러나 어떻게 양자화 된 모델을 얻을 수 있습니까? Core ML 형식의 뉴럴 네트워킹을 사용하는 경우 Core ML Tools를 사용하여 양자화 된 표현을 얻을 수 있습니다.
 따라서 코어 ML 2는 자동으로 퀀 타이즈해야합니다.
 또는 양자화 된 모델을 학습 할 수 있습니다.
 양자화 제약 조건을 처음부터 다시 적용하거나 양자화 제약 조건을 사용하여 기존 모델을 재 훈련 할 수 있습니다.
 교육 도구로 양자화 된 모델을 얻은 후에 평소처럼 Core ML로 변환 할 수 있습니다.
 그리고 당신이 모델을 사용하는 방식으로 앱에서 변화 할 것은 없습니다.
 모델 내에서 숫자는 다른 정밀도로 저장되지만 모델을 사용하기위한 인터페이스는 전혀 변경되지 않습니다.
 그러나 양자화 된 모델은 원본 참조 부동 소수점 모델의 정밀도가 낮은 근사치를 항상 고려해야합니다.
 그리고 이것은 양자화 된 모델이 모델 대비 크기와 정확성을 제공한다는 것을 의미합니다.
 이 절충안은 모델에 따라 다르며 유스 케이스에 따라 다릅니다.
 또한 매우 활발한 연구 분야이기도합니다.
 따라서 양자화 된 모델의 정확성을 검사하고 해당 데이터 및 앱 및 유스 케이스에 유효한 양식 메트릭에 대해 참조 된 부동 소수점 버전과 비교하는 것이 좋습니다.
 이제 우리가 사용할 수있는 방법에 대한 데모를 보도록하겠습니다. 양자화 된 모델을 채택하여 앱의 크기를 줄입니다.
 스타일 전송 앱을 보여 드리고 싶습니다.
 스타일 전송에서 신경망은 그림이나 다른 이미지를 보면서 습득 한 스타일을 사용하여 사용자 이미지를 렌더링하도록 훈련되었습니다.
 그래서 내 애플 리케이션을로드하자.
 우리가 볼 수 있듯이, 나는 4 가지 스타일로이 앱을 선적 중이다. 도시, 유리, 오일 및 파도.
 그런 다음 사용자의 사진 라이브러리에서 이미지를 선택한 다음 장치에서 다양한 스타일로 이미지를 혼합하여 처리 할 수 ​​있습니다.
 그래서 이것이 원래의 이미지이고, 저는 City 스타일, 유리, 오일, 그리고 웨이브를 렌더링 할 것입니다.
 Xcode에서이 앱이 어떻게 빌드되었는지 보도록하겠습니다.
 이 응용 프로그램은 CoreML 및 Vision API를 사용하여이 양식을 수행합니다.
 그리고 우리가 볼 수 있듯이 Xcode에 번들로 제공되는 4 개의 Core ML 모델이 있습니다. City, Glass, Oils, Waves 등이 있습니다.
 그리고 우리는이 모델을 검사 할 수 있음을 알 수 있습니다.
 이것들은 양자화 된 모델로 보여 지므로이 모델들 각각은 6입니다.
디스크에이 공간의 7 메가 바이트.
 모델은 특정 해상도의 입력 이미지를 가져 와서 같은 해상도의 스타일 화 된 이미지를 생성합니다.
 이제 우리가 사용할 수있는 저장 공간과 메모리 공간이 얼마나되는지 조사하고 싶습니다. 양자화 된 모델로 전환하여 저장할 수 있습니다.
 그래서 Core ML Tools를 가지고 놀았고이 모델들을위한 양자화 된 프리젠 테이션을 얻었습니다.
 그리고이 모델을 얻는 방법에 대한 자습서를 보려면 Part 2에서 Core ML Tools로 양자화를 상세히 다루십시오.
 그래서 저는 Glass 스타일에 우선 초점을 맞추고이 양자화 버전에 대해 다른 양자화 버전이 어떻게 작동하는지 살펴 보겠습니다.
 따라서이 새로운 모델을 Xcode 프로젝트 내부로 드래그하고 앱을 다시 실행하기 만하면됩니다.
 그리고 나서 우리는이 모델들이 어떻게 행동하는지 볼 것입니다.
 처음에는 크기가 크게 줄어들 었음을 알 수 있습니다.
 예를 들어, 이미 6 또는 7 메가 바이트의 8 비트 버전은 1로 내려갔습니다.
7.
 4 비트에서는 훨씬 더 절약 할 수 있습니다. 이제 모델은 1 메가 바이트 미만입니다.
 3 비트에서는 49 킬로바이트로 훨씬 작습니다.
 등등.
 이제 앱으로 돌아가 보자.
 이 이미지를 참고 용으로 만들어 Glass 버전을 원본 버전에 적용 해 보겠습니다.
 이전과 같이 여전히 보입니다.
 이제이를 8 비트 버전과 비교할 수 있습니다.
 그리고 당신은 아무것도 변화하지 않은 것을 볼 수 있습니다.
 이는 8 비트 양자화 방법이 매우 견고하기 때문입니다.
 우리는 더 나아가서이 모델의 4 비트 버전을 시도 할 수도 있습니다.
 와우.
 결과는 여전히 훌륭합니다.


이제 3 비트 버전을 사용해 봅시다.
 우리는 첫 번째 색상 이동을 봅니다.
 따라서 우리가 가서이 효과가 여전히 받아 들여지면 설계자와 확인해 보는 것이 좋습니다.
 이제 2 비트 버전을 볼 때 이것은 실제로 우리가 원하는 것이 아닙니다.
 어쩌면 우리는 호러 애플 리케이션을 위해 그것을 저장할 것이지만, 나는 이것을 디자이너에게 보여주지 않을 것이다.
 4 비트 버전으로 돌아가서이 버전을 숨 깁니다.
 이것은 양자화 된 모델이 원래 모델의 근사치임을 상기시키는 것입니다.
 따라서 항상 확인하고 원래 버전과 비교하는 것이 좋습니다.
 이제 모든 모델 및 양자화 기술에 대해 항상 불일치가 발생하는 지점이 있습니다.
 이제 우리는 디자이너와의 토론, 많은 이미지의 광범위한 평가를 거쳐이 모델의 4 비트 버전을 출하하기로 결정했습니다.이 모델은 최상의 품질을위한 가장 작은 크기입니다.
 이제 우리의 앱에서 많은 공간을 차지하고 4 비트 버전으로 대체 한 모델의 부동 소수점 버전을 모두 제거해 보겠습니다.
 마지막으로 앱을 실행 해 보겠습니다.
 승인.
 같은 이미지를 다시 선택하고 모든 스타일을 보여줍니다.
 이것은 City, Glass, Oils 및 큰 파도였습니다.
 이 데모에서는 4 가지 모델로 시작한 방법을 보았습니다.이 모델은 32 비트에서 거대했습니다. 전체 앱 크기는 27 메가 바이트였습니다.
 그런 다음 품질을 평가하고 4 비트 모델로 전환했으며 앱의 전체 크기는 3에 불과했습니다.
4 메가 바이트.
 이제 -이 모든 버전 (양자화 된 버전은 동일하게 보이고 품질은 여전히 ​​놀랍기 때문에 품질 측면에서 우리에게 비용이 들지 않습니다.)
 우리는 양자화가 매우 미세한 수준에서 체중의 크기를 줄임으로써 앱의 크기를 줄이는 데 어떻게 도움이되는지 보여 줬습니다.
 이제 앱이 필요로하는 모델의 수를 줄이는 방법을 알아 보겠습니다.
 가장 간단한 경우, 앱에 세 가지 기계 학습 기능이있는 경우 세 가지 다른 기계 학습 모델이 필요합니다.
 그러나 경우에 따라 두 모델을 지원하는 동일한 모델을 사용할 수도 있습니다.
 예를 들어, 다중 작업 모델을 학습 할 수 있습니다.
 또한 다중 작업 모델은 여러 가지 작업을 한 번에 수행 할 수 있도록 교육을 받았습니다.
 스타일 이전에 대한 예가 있으며, 다중 작업 모델에 대한 Turi Create 세션이 있습니다.
 또는 어떤 경우에는 유연한 모양 및 크기라는 Core ML의 새로운 기능을 사용할 수 있습니다.
 Style Transfer 데모로 돌아가겠습니다.
 Xcode에서 우리는 입력 이미지와 출력 이미지의 크기가 모델 정의의 일부로 인코딩되었음을 확인했습니다.
 그러나 다른 이미지 해상도에서 같은 스타일을 실행하고 싶다면 어떻게해야할까요? 서로 다른 이미지 크기로 동일한 네트워크를 실행하려면 어떻게해야할까요? 예를 들어, 사용자는 HD 스타일 전송을 원할 수 있습니다.

그래서 그들은 사용합니다 - 그들은 우리에게 고선명 이미지를줍니다.
 이제 코어 ML 모델이라면 입력으로 더 낮은 해상도가됩니다. 개발자가 할 수있는 모든 것이 크기이거나 이미지 크기를 조정하고 처리 한 다음 다시 크기를 조정합니다.
 이것은 실제로 사용자를 놀라게하지 않습니다.
 과거에도 Corel ML Tools를 사용하여이 모델을 다시 불러 들일 수 있었으며 특히 해상도가 높은 이미지를 수용 할 수있었습니다.
 따라서 과거에도이 기능을 사용하여 고해상도 이미지를 Corel ML 모델에 직접 제공하여 고선명 결과를 얻을 수있었습니다.
 이는 최종 이미지에 많은 작업을 추가하기 때문에 확대했을 때 놀라운 파인더와 획기적인 획을 자세하게 소개하고자했기 때문입니다.
 그래서 과거에는 할 수 있었지만 모델을 복제하고 두 가지 버전을 만들었습니다. 하나는 표준 정의 용이고 다른 하나는 고화질 정의 용입니다.
 물론 이것은 네트워크가 모든 해결책을 지원할 수 있도록 훈련 된 사실 외에도 우리 앱의 크기가 두 배나 큰 것을 의미합니다.
 더 이상.
 우리는 유연한 모양을 도입하고 있습니다.
 유연한 모양을 사용하면 더 많은 해상도와 더 많은 해상도를 처리 할 수있는 단일 모델을 보유 할 수 있습니다.
 이제 Xcode에서는 Xcode에서 입력이 여전히 이미지이지만 전체 해상도의 크기 인 유연한 해상도를 사용할 수 있음을 알게 될 것입니다.
 이 간단한 예에서는 SD와 HD가 있습니다.
 즉, 단일 모델을 발송해야합니다.
 중복 된 코드가 필요하지 않습니다.
 표준 정의와 고화질을 전환해야하는 경우 모델을 처음부터 다시로드 할 필요가 없기 때문에 훨씬 빠르게 수행 할 수 있습니다. 크기를 조정하면됩니다.
 모델의 유연성을 지정하는 두 가지 옵션이 있습니다.
 치수의 범위를 정의 할 수 있으므로 최소 너비와 높이, 최대 너비와 높이를 정의 할 수 있습니다.
 그리고 추론을하면서 그 사이의 어떤 값을 선택하십시오.
 그러나 또 다른 방법이 있습니다.
 당신은 당신이 사용하려고하는 모든 모양을 열거 할 수 있습니다.
 예를 들어, 모든 종횡비와 모든 해상도가 다를 수 있으며 이는 성능 향상에 도움이됩니다.
 Core ML은 유스 케이스에 대해 더 많이 알고 있기 때문에 더 많은 최적화를 수행 할 수 있습니다.
 또한 앱에 작은 테스트 표면을 제공합니다.
 이제 어느 모델이 유연합니까? 여러 모델을 지원하기 위해 어떤 모델을 교육 할 수 있습니까? 스타일 컨버전, 이미지 향상, 수퍼 해상도 등과 같은 MS 처리 작업에 일반적으로 사용되는 완전 컨볼 루션 (convolutional) 신경망 - 그리고 일부 아키텍처.
 핵심 ML 도구는 모델에이 기능이 있는지 확인할 수 있습니다.
 따라서 우리는 여전히 Core ML이 유연한 크기로 사용하는 모델의 수를 가지고 있으며, 가중치의 크기는 양자화로 줄일 수 있습니다.
 그러나 무게의 수는 어떻습니까? Core ML은 모든 프레임 워크에서 많은 다양한 아키텍처를 지원한다는 점을 감안할 때 항상 기계 학습 문제에 적합한 크기의 모델을 선택할 수 있도록 도와주었습니다.
 따라서 Core ML은이 세 가지 요소를 사용하여 앱의 크기를 조정하는 데 도움을 줄 수 있습니다.
 어쨌든, 추론은 훌륭한 수행자가 될 것입니다.
 그리고 성능 및 사용자 정의에 새로운 기능을 도입하기 위해 Bill March을 환영합니다.
 고맙습니다.
  고맙습니다.
 맨 처음부터 Core ML의 근본적인 디자인 원칙 중 하나는 앱에 최상의 성능을 제공해야한다는 것입니다.
 그리고 그 목표에 부합하기 위해 Core ML의 새로운 기능을 강조하여 귀하의 응용 프로그램이 모든 Apple 장치에서 빛나게 해드립니다.
 Francesco가 우리에게 보여준 스타일 이전 예제를 살펴 보겠습니다.
 앱의 관점에서 입력 이미지를 가져 와서 양식 된 이미지를 반환하기 만하면됩니다.
 그리고 두 가지 핵심 구성 요소가 있습니다 : 첫 번째,이 스타일을 적용하는 데 필요한 특정 매개 변수를 저장하는 MLModel 파일. 둘째, 추론 엔진은 MLModel과 이미지를 받아들이고 결과를 산출하는 데 필요한 계산을 수행합니다.
 따라서이 추론 엔진의 엿보기를 들여다 보면서이 스타일 전송을 효율적으로 수행하기 위해 Apple의 기술을 어떻게 활용하는지보십시오.
 이 모델은 레이어라고하는 일련의 수학 연산으로 구성된 신경망의 예입니다.
 각 레이어는 이미지에 일부 변형을 적용하여 최종적으로 양식화 된 출력을 만듭니다.
 모델에는 특정 변환 및 적용 할 스타일을 결정하는 각 레이어의 가중치가 저장됩니다.
 코어 ML 신경망 추론 엔진은 이들 각각의 계층에 대해 고도로 최적화 된 구현을 갖는다.
 GPU에서는 MTL 셰이더를 사용합니다.
 CPU에서 능숙한 계산 인 Accelerate를 사용할 수 있습니다.
 또한 모델, 장치 상태 및 기타 요인에 따라 계산의 다른 부분을 동적으로 다른 하드웨어 조각에 전달할 수 있습니다.

우리는 네트워크에서 레이어를 융합 할 수있는 기회를 찾을 수 있기 때문에 필요한 전체 계산이 줄어 듭니다.
 우리는 무슨 일이 일어나고 있는지 알기 때문에 여기에서 최적화 할 수 있습니다.
 우리는 모델의 세부 사항을 알고있다. 그들은 당신이 우리에게 제공 한 MLModel 파일에 포함되어 있습니다.
 추론 엔진과 장치에 대한 세부 사항은 설계했기 때문에 알 수 있습니다.
 이러한 모든 최적화 작업을 처리 할 수 ​​있으며 앱에서 최상의 사용자 환경을 제공하는 데 주력 할 수 있습니다.
 하지만 당신의 작업량은 어떻습니까? 특히 여러 예측을해야하는 경우에는 어떻습니까? 코어 ML이 그것에 대해 알지 못한다면, 코어 ML은이를 최적화 할 수 없습니다.
 과거에는 이와 같이 워크로드가 있다면 다음과 같은 작업을 수행해야했습니다. 기존 Core ML 예측 API를 호출하는 간단한 for 루프.
 그래서 여러분은 어떤 배열의 입력을 루프 처리하고 일련의 출력을 생성 할 것입니다.
 후드 아래에서 일어나는 일에 대해 자세히 살펴 보도록하겠습니다.
 각 이미지에 대해 사전 처리 작업을 수행해야합니다.
 다른 것이 없다면 데이터를 GPU로 보내야합니다.
 일단 우리가 계산을하고 출력 이미지를 만들 수 있습니다.
 하지만 GPU에서 데이터를 가져 와서 앱에 반환해야하는 후 처리 단계가 있습니다.
 이 그림을 개선하는 열쇠는 GPU 파이프 라인의 거품을 제거하는 것입니다.
 그 결과 크게 두 가지 이유에서 성능이 향상됩니다.
 첫째, GPU가 유휴 상태 인 시간이 없으므로 전체 계산 시간이 단축됩니다.
 둘째, GPU가 지속적으로 작동하기 때문에 고성능 상태에서 작동하고 각 특정 출력을 계산하는 데 필요한 시간을 단축 할 수 있습니다.
 그러나 Core ML의 매력은 당신이이 같은 세부 사항에 대해 전혀 걱정할 필요가 없다는 것입니다.
 실제로 앱에서 사용자가 실제로 염려하는 것은 결과를 얻는 데 오랜 시간이 걸리는 것입니다.
 그래서 올해 우리는 당신이 정확하게 이것을 할 수있게 해주는 새로운 배치 API를 소개 할 것입니다.
 이전에 입력을 반복하고 별도의 예측을 호출해야했던 경우 새 API는 매우 간단합니다.
 한 줄 예측을 통해 입력 배열을 생성하고 출력 배열을 생성합니다.
 코어 ML은 나머지를 처리 ​​할 것입니다.
 그럼 실제로 보자.
 따라서 스타일 전송 예제를 유지하면서 전체 사진 라이브러리에 스타일을 적용하려는 경우를 살펴 보겠습니다.
 그래서 여기에 그저 그렇게 할 간단한 앱이 있습니다.
 저는 200 개의 이미지에 스타일을 적용 할 것입니다.
 왼쪽에는 왼쪽 에서처럼 for 루프에서 작년의 API를 사용하는 구현이 있습니다.
 그리고 오른쪽에는 새로운 배치 API가 있습니다.
 시작하겠습니다.
 우리는 벗어났다.
 그리고 우리는 이미 새로운 것을 볼 수 있습니다.
 우리는 작년 기술에 대한 잠시 동안 기다릴 것이고 거기에 우리가 갈 것입니다.
 이 예제에서는 새로운 배치 API를 사용하여 눈에 띄는 향상을 볼 수 있습니다.
 일반적으로 앱에서 개선되는 부분은 모델, 기기 및 작업량에 따라 다릅니다.
 그러나 전화 할 예측이 많으면 새로운 API를 사용하고 Core ML에게 계산을 가속화 할 수있는 모든 기회를 제공하십시오.
 물론 세계에서 가장 뛰어난 성능의 앱은 사용자에게 필요한 경험을 제공하지 않는다면별로 흥미롭지 않습니다.
 우리는 그 경험이 무엇이든 미래에있을지라도 코어 ML은 그 어느 때보 다 사용하기 쉽고 단순합니다.
 그러나 기계 학습 분야는 빠르게 성장하고 있습니다.
 우리는 어떻게 계속 할 것인가? 얼마나 빨리? 그럼 저에 대한 개인적인 이야기를 조금하겠습니다.
 우리가 기계 학습을 통해 대답 할 수있는 믿을 수 없을만큼 간단한 질문을 살펴 보겠습니다.
 이미지가 주어지면 내가 알고 싶은 것 : 그 안에 말이 있습니까? 그래서 나는 낄낄 거리는 소리를 들었다고 생각합니다.
 어쩌면 이것은 어리석은 도전 문제와 같을 수도 있습니다.
 작은 아이들은 그런데 이걸 좋아합니다.
 그런데 다시 과거로 돌아가서 제가 대학원을 처음 시작했을 때이 문제와 기계 학습에 대해 먼저 배웠을 때, 정상에 대한 나의 통찰력은 다음과 같았습니다 : 나는 모른다. - 열심히 보인다.
 나는 너에게 좋은 아이디어가 없다.
 그래서 몇 년이 지났습니다.
 나이가 들었습니다. 조금만 더 현명하게.
 그러나 깊은 신경 네트워크를 사용하여 흥미 진진한 결과가 많이 나오기 시작했기 때문에이 분야는 매우 빠르게 움직이고 있습니다.
 그리고 나서이 문제에 대한 내 견해가 바뀌 었습니다.
 갑자기, 와우,이 최첨단 연구는 이러한 종류의 질문에 실제로 대답 할 수 있으며, 컴퓨터는 어린이와 말 인식 기술을 따라 잡을 수 있습니다.
 이 얼마나 흥미 진진한 개발.
 그래서 몇 년이 더 지납니다.
 이제 저는 Apple에서 일하고 있으며,이 문제에 대한 저의 시각은 다시 변했습니다.
 이제 Create ML을 잡으십시오.
 UI가 멋지다.
 몇 분 안에 말 분류기를 사용할 수 있습니다.

그래서, 당신이 기계 학습 전문가라면 어쩌면 당신은 이것을보고 있고 당신은 생각하고 있습니다. "오,이 남자는 그가 말하는 것을 모른다.
 2007 년에 나는 그 문제를 해결하는 방법을 알고있었습니다.
 2012 년에 나는 그것을 100 번 풀었습니다.
"내 말은 아니다.
 오랫동안 지속되는 고품질의 소프트웨어에 관심이있는 사람이라면 11 년 후에이 문제의 전체적인 모습이 바뀌어서 긴장감을 느낄 것입니다.
 이제 마음을 편안하게 할 수있는 Core ML의 몇 가지 기능에 대해 살펴 보겠습니다.
 그렇게하기 위해 두 번 다시 열어 보자.이 새로운 말 찾기 모델 중 하나를 살펴 보자. 다시 말하면 신경망이다.
 이전에 설명했듯이 신경망은 고도로 최적화 된 일련의 레이어로 구성됩니다.
 그것은 일련의 레이어이며 우리는 우리의 추론 엔진에서 각각에 대해 매우 최적화 된 구현을 가지고 있습니다.
 지원되는 사업 목록은 규모가 크며 항상 성장하고 있으며 현장의 새로운 개발 상황을 따라 잡기 위해 노력하고 있습니다.
 코어 ML에서 지원되지 않는 레이어가 있다면 어떻게 될까요? 과거에는 기다릴 필요가 있었거나 다른 모델이 필요했습니다.
 그러나이 레이어가 핵심적인 말 찾기 레이어라면 어떨까요? 이것은 말의 앱이 기다리고 있던 돌파구입니다.
 기다릴 여유가 있습니까? 기계 학습의 속도를 감안할 때 이것은 심각한 장애물이 될 수 있습니다.
 그래서 우리는 신경망 모델을위한 맞춤 레이어를 도입했습니다.
 이제 신경망 계층이 누락 된 경우 - will이 코어 ML 모델의 나머지 부분과 매끄럽게 연결될 수있는 구현을 제공 할 수 있습니다.
 모델 내에서 사용자 정의 계층은 구현 클래스의 이름 (이 경우에는 AAPLCustomHorseLayer)을 저장합니다.
 구현 클래스는 누락 된 구현의 역할을 추론 엔진에서 채 웁니다.
 레이어가 Core ML에 내장 된 것처럼 여기에 제공된 구현은 일반적이어야하며 새 레이어의 모든 인스턴스에 적용 할 수 있어야합니다.
 런타임시 앱에 포함하기 만하면됩니다.
 그런 다음이 특정 레이어의 매개 변수가 모델에 대한 나머지 정보와 함께 ML 모델에 캡슐화됩니다.
 맞춤 레이어를 구현하는 것은 간단합니다.
 우리는 MLCustomLayer 프로토콜을 공개합니다.
 ML 모델에 저장된 데이터를 기반으로 레이어를 초기화하는 메소드를 제공하기 만하면됩니다.
 레이어의 출력에 할당 할 공간의 양을 알려주는 메서드를 제공 한 다음 계산을 수행하는 메서드를 제공해야합니다.
 또한 모델 전체의 성능을 희생하지 않고도 이러한 유연성을 추가 할 수 있습니다.
 프로토콜에는 모델의 MTL 쉐이더 구현을 제공 할 수있는 선택적인 메서드가 포함되어 있습니다. 즉 레이어의 실례입니다.
 우리에게 이걸 주면 나머지 코어 ML 계산과 같은 명령 버퍼에서 인코딩 될 수 있습니다.
 따라서 GPU를 오가는 추가 인코딩이나 GPU를 여러 번 사용하면 추가 오버 헤드가 없습니다.
 이 값을 제공하지 않으면 우리는 단순히 CPU의 레이어를 다른 작업없이 평가할 수 있습니다.
 따라서 신경망 모델의 발전 속도가 아무리 빨라지더라도 Core ML을 따라 잡을 수있는 방법이 있습니다.
 그러나 한계가 있습니다.
 맞춤 레이어는 신경망 모델에서만 작동하며 ML MultiArrays 인 입력과 출력 만 가져옵니다.
 이것은 신경망과 상호 작용하는 자연스러운 방법입니다.
 그러나 기계 학습 분야는이 분야에서만 발전하는 데 거의 제한되지 않습니다.
 사실 이미지 인식에 대해 처음 알았을 때 그 문제에 대한 해결책으로 신경망에 대해 이야기하는 사람은 거의 없었습니다.
 그리고 당신은 그것이 오늘날 예술의 절대 상태임을 알 수 있습니다.
 그리고 맞춤 레이어가 적합하지 않은 곳에서 기계 학습이 가능한 앱 환경을 상상하는 것이 어렵지 않습니다.
 예를 들어, 기계 학습 응용 프로그램은 신경망을 사용하여 유사 공간에 이미지를 포함시킨 다음 가장 가까운 이웃 방법 또는 지역에 민감한 해싱을 사용하여 유사한 이미지를 찾거나 다른 방법을 사용할 수 있습니다.
 모델은 오디오 및 모션 데이터를 결합하여 항상 자신의 링을 닫지는 않는 사람에게 약간의 격려를 제공 할 수 있습니다.
 심지어 우리가 아직 상상조차하지 못했던 완전히 새로운 모델 유형은 사용자에게 새로운 경험을 가능하게합니다.
 이러한 모든 경우에있어 현장에서 유지하기 위해 융통성을 희생하지 않고도 Core ML의 간편성과 휴대 성을 확보 할 수 있다면 좋을 것입니다.
 그래서 우리는 사용자 정의 모델을 도입하고 있습니다.
 코어 ML 사용자 정의 모델을 사용하면 코어 ML 내부에 누락 된 계산의 일부분을 캡슐화 할 수 있습니다.
 사용자 정의 레이어와 마찬가지로 모델에는 구현 클래스의 이름이 저장됩니다.
 클래스는이 유형의 모델에 대한 일반 유추 엔진의 역할을 채 웁니다.
 그런 다음 이전과 마찬가지로 매개 변수가 ML 모델에 저장됩니다.
 이를 통해 코드를 건드리지 않고도 모델을 앱의 자산으로 업데이트 할 수 있습니다.
 그리고 커스텀 모델을 구현하는 것도 간단합니다.
 MLCustomModel 프로토콜을 공개합니다.

ML 모델에 저장된 데이터를 기반으로 초기화하는 메소드를 제공합니다.
 그리고 입력에 대한 예측을 계산하는 방법을 제공합니다.
 이 특정 모델 유형에 최적화가있을 기회가있는 경우 배치 구현을 제공하는 선택적 방법이 있습니다.
 그렇지 않은 경우 for 루프에서 단일 예측을 호출합니다.
 앱에서 맞춤 모델을 사용하는 것은 다른 Core ML 모델과 거의 동일합니다.
 Xcode에서 사용자 정의 된 구성 요소가있는 모델에는 간단한 설명과 함께 필요한 구현 이름이 나열된 종속성 섹션이 있습니다.
 앱에이를 포함 시키면 바로 사용할 수 있습니다.
 예측 API는 단일 예측 또는 일괄 처리에 상관없이 변경되지 않습니다.
 따라서 커스텀 레이어와 커스텀 모델은 빠르게 변화하는 기계 학습 영역을 따라 잡는 데 필요한 유연성을 희생하지 않고도 Core ML의 강력 함과 단순함을 사용할 수있게 해줍니다.
 새로운 신경망 레이어의 경우 사용자 지정 레이어를 사용하면 Core ML의 신경망 추론 엔진에 이미있는 많은 최적화를 사용할 수 있습니다.
 사용자 정의 모델은 유형 및 기능에 대해보다 유연하지만 사용자가 더 많은 구현 작업을해야합니다.
 두 가지 형식의 사용자 정의를 통해 모델 매개 변수를 ML 모델에 캡슐화 할 수 있으므로 모델을 이식성 있고 코드를 간단하게 만들 수 있습니다.
 그리고 우리는 Core ML 2의 몇 가지 훌륭한 새로운 기능을 접할 수있었습니다.
 베타 버전을 다운로드하여 직접 사용해보십시오.
 Core ML에는 앱 크기를 줄이고 성능을 향상 시키며 기계 학습의 최신 개발과의 호환성 및 호환성을 보장하는 여러 가지 새로운 기능이 추가되었습니다.
 퀀 타이즈가 모델 크기를 줄이는 방법, 새로운 배치 API가보다 효율적인 처리를 가능하게하는 방법, 커스텀 레이어와 커스텀 모델이 여러분의 앱에 최첨단 기계 학습을 가져 오는 방법을 보여주었습니다.
 Create ML의 교육용 모델을위한 훌륭한 새 도구와 결합하여, ML 지원 기능을 앱에 추가하고 사용자에게 새로운 경험을 제공 할 수있는 다양한 방법이 있습니다.
 잠시 휴식을 취한 후에 바로 이러한 기능 중 일부를 자세히 살펴볼 것입니다.
 특히 Core ML Tools 소프트웨어를 사용하여 모델 크기를 줄이고 오늘날 Core ML로 사용자 경험을 커스터마이징하는 방법을 알려드립니다.
 고맙습니다.
