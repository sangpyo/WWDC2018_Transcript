좋은 아침, 너와 함께하는 것이 기쁘다.
 저는 Emmanuel이며 Core Image 팀의 엔지니어입니다.
 오늘 아침 깊이를 사용하여 사진 및 비디오 효과를 만드는 방법을 살펴 보겠습니다.
 시작하자.
 iOS 11을 사용하여 세로 형 스틸 이미지와 함께 세로 형 깊이 데이터를 제공하기 시작했습니다.
 작년의 WWDC 세션에서 우리는 힘의 관점, 시뮬레이션 된 심도의 효과, 다양한 전경 및 배경 분리 효과와 같은 놀라운 효과를 얻기 위해 깊이 데이터를 활용하는 방법을 보여주었습니다.
 올해 우리는 새로운 기능인 인물 매트를 발표 할 것을 매우 기쁘게 생각합니다.
 그래서 이번 세션의 전반부에서는 초상화의 정지 이미지에 초점을 맞출 것이고, 당신은 어떻게 그들에게 정말 큰 효과를 적용 할 수 있을지에 대해 이야기 할 것입니다.
 내 동료 인 Ron Over Video Engineering은 TrueDepth 카메라를 사용하여 실시간 비디오 효과를 얻는 데 중점을 둘 것입니다.
 자, 초상화 세분화 API를 살펴 보겠습니다.
 그래서 나는 초상화 매트를 언급했다. 그래서 초상화 매트는 무엇인가? 초상화 무광택은 전경에서 배경까지 세그멘테이션이며, 이것은 정확히 1이라는 마스크를 가졌다는 것을 의미합니다.
전경 0 및 0.
0을 선택하면 부드럽고 연속적인 값을 얻을 수 있습니다.
 인물 사진의 무광택 화질은 매우 뛰어나며 피사체의 윤곽선에 컬이나 머리카락 같은 세부 묘사를 유지할 수 있습니다.
 이것은 놀랍다.
 매트는 많은 효과를 내기 위해 사용할 수 있습니다. 여기에는 배경을 어둡게하여 전경과 배경을 분리하는 작업 중 하나가 있습니다.
 그러나 우리는이 도구를 손에 넣기 때문에 놀라운 응용 프로그램과 새로운 효과를 만들 수 있고 사용자를 기쁘게 할 수 있습니다.
 좋아, 그럼 인물 효과 매트가 아이폰 OS 12에서 나올거야.
 전면 및 후면 카메라 모두에 사용할 수 있습니다.
 인물 사진이있는 장면을 볼 수 있으며 현재 장면에 사람이있을 때만 볼 수 있습니다.
 인물 사진의 매트는 선형으로 인코딩되므로 감마 인코딩되지 않으며 그레이 스케일 버퍼가 있습니다.
 또한 인물 사진의 정지 이미지와 함께 인물 사진을 찍을 수 있다는 보장이 없으며 항상 깊이 데이터를 얻지 만 그 존재 여부를 테스트해야합니다.
 API를 살펴보고 데이터를 실제로로드하는 방법에 대해 살펴 보겠습니다.
 따라서 ImageIO는 인물 효과 매트를로드 할 수있는 로우 레벨 API를 제공합니다.
 그래서 CGImageSourceCopy를 호출하면 kCGImageAuxiliaryData TypePortraitEffectsMatte를 전달할 수있는 새로운 키가 생깁니다.
 그리고이 호출은 세 가지 주요 정보를 포함하는 사전을 반환합니다.
 이미지 데이터 자체를 CFDataRef로, 캡처 자체에 관련된 메타 데이터뿐 아니라 CFDictionary로 버퍼 자체에 속한 메타 데이터.
 또한 AVFoundation은 당신이 사용할 수있는 ImageIO 위에 위치하는 더 높은 수준의 API를 제공합니다.
 따라서 CGImageSourceCopy에서 출력을 가져 와서 AVPortrait 효과 매트 클래스에 공급할 수 있습니다.
 그리고 당신이 얻는 것은 매우 간단합니다. 그것은 CV 형식의 픽셀 버퍼와 함께 CV 형식의 픽셀 버퍼를 사용할 수 있기 때문에 추가 프로세싱 요구에 사용할 수 있습니다. 정말 간단합니다.
 또한 AVFoundation은 캡처시에 세로 방향 매트 전달을 지원합니다.
 따라서 AVCaptureInput, 장치 및 캡처 세션으로 일반적인 AVFoundation 설정부터 시작하십시오.
 가장 먼저하고 싶은 일은 환경에서 인물 효과 매트를 전달할 수 있는지 확인하는 것입니다.
 이렇게하려면 데이터 전송이 지원되는지뿐만 아니라 인물 효과 매트 전송이 지원되는지 확인해야합니다.
 우리가 깊이와 인물 효과를 모두 가지고있는 이유는 그들이 함께 모인다는 것입니다.
 깊이 데이터 만 가져 오도록 선택할 수도 있지만 인물 효과 매트가 필요할 때마다 깊이 데이터 전달을 활성화해야합니다.
 활성화 시키거나 배달을 선택하려면 AVCapturePhotoSettings를 수정하고 isPortraitEffects MatteDelivery를 사용하도록 설정하고 isDepthDataDeliveryEnabled를 true로 설정하십시오.
 그런 다음 ddiFinishProcessingPhoto 콜백 캡처 시간에 인물 효과 매트가 나타납니다.
 정말 간단합니다.
 모든 오른쪽 코어 이미지는 인물 효과 매트를로드하고 저장하는 방법을 제공합니다.
 새로운 큐가 도입되었습니다. auxiliaryPortrait EffectsMatte는 URL의 내용으로 이미지를 전달하고 초상화 효과가 포함 된 CI 이미지를 다시 가져옵니다.
 코어 이미지를 사용하면 인물 효과 매트를 파일에 직접 저장할 수도 있습니다.
 이렇게하려면 portraitEffectsMatteImage라는 새 컨텍스트 옵션이 있습니다. 세로 효과 매트가 포함 된 CI 이미지를 전달한 다음 writeHEIFRepresntationOfImage를 사용하여 파일을 디스크에 쓸 수 있습니다.
 좋습니다. 여기서 주목해야 할 것은 RGB, 깊이 버퍼 및 세로 매트 버퍼가 서로 다른 해상도로 살아 있도록 세 개의 이미지가 있다는 것입니다.

예를 들어 뒤쪽 카메라의 세로 방향 매트는 절반 크기이며 깊이 데이터는 훨씬 작습니다.
 따라서 카메라를 뒤쪽으로 향하게 한 경우 이미지를 나란히 보도록하겠습니다.
 이는 응용 프로그램에서 RGB 이미지를 세로 또는 세로 방향 매트 크기 또는 [들리지 않음] 크기로 다운 샘플링하고 RGB 이미지의 크기로 샘플링해야 함을 의미합니다.
 이제 인물 세분화 API에 대해 오늘 이야기하고 싶었습니다. 우리는이 장면을 실제로 볼 수있는 훌륭한 데모를 가지고 있습니다.
 그래서이 데모에서는 파이썬을위한 브라우저 기반의 실시간 인터프리터 인 목성 노트를 사용할 것입니다.
 Core Image에 Python 바인딩을 사용하게 될 것입니다. 오늘은 별도의 세션에서 소개 할 것입니다.
 그러니 초상화 깊이와 인물 매트가 들어있는 이미지를 시작하고로드 해 봅시다.
 이것이 우리가 작업하게 될 이미지입니다.
 내가 보여주고 싶은 첫 번째 것은 그 이미지에 깊이 데이터가 어떻게 보이는지입니다. 그래서 두 가지를 나란히 보겠습니다.
 그래서 우리는 왼쪽에 세로 깊이가 있고 오른쪽에 세로 방향 매트가 있습니다. 그러면 세부 사항이 얼마나 미세한 지 알 수 있습니다.
 그리고 우리는 단 몇 분 안에 확대 자르기를 수행하여 얼마나 높은 품질인지 더 잘 판단 할 수 있습니다.
 다음으로 할 일은 이미지의 크기를 조정하는 것입니다.
 보시다시피 RGB와 깊이 데이터의 크기는 크게 다릅니다.
 그래서 우리는 이미지의 크기를 조정하고 나란히 보도록하겠습니다.
 그래서 우리는 RGB와 깊이 데이터를 오른쪽에 가지고 있습니다.
 이 데모의 첫 부분에서는 깊이 데이터에 중점을두고 인물 이펙트 매트를 사용할 때 상황이 훨씬 더 간단 해지는 것을 보게 될 것입니다.
 오늘 제가 작업하게 될 효과는 깊이 thresholding이며 본질적으로 제가하고있는 일은 제 초상화 깊이의 그레이 레벨 값의 막대 그래프를 계산하는 것입니다.
 그리고 히스토그램에 임계 값이나 클리핑 포인트를 적용하여 임계 값 아래 또는 위에있을 때 모든 것이 0 또는 1이되도록합니다.
 그런 다음 형태학적인 닫는 연산을 사용하여 이미지의 구멍을 닫은 다음 마스크를 흐리게 처리하여 멋진 깃털 모양을 얻습니다.
 이것을 실제로 보도록하겠습니다.
 따라서이 모든 것이 코어 이미지를 백엔드로 사용하여 브라우저에서 실시간으로 실행된다는 것을 기억하십시오.
 좋습니다. 그래서 내가 보여주고 싶은 첫 번째 것은 백분위 점을 변경하면 마스크가 어떻게 바뀌는 지입니다.
 그래서 높을수록 덜 공격적입니다 전경을 클리핑하고 있습니다.
 합리적인 가치를 선택해 봅시다.
 여기서 볼 수있는 것은 우리가 전경에 연결되어있는 지역 또는 섬이 있고 여기에 제가 꺼내고 싶은 주제가 조금 있습니다.
 그래서 제가 할 일은 형태 론적 폐쇄를 조금 추가 할 것입니다.
 이것이 어떻게 마술처럼 보일지보십시오.
 나가 너무 멀리 명백하게가는 경우에, 나는 전체적인 주제를 잃는다, 나는 그것을하고 싶지 않다.
 그래서 이런 것을 고집합시다.
 내가 할 수있는 일은 그 위에 마스크를 적용하여 페더 링을 변경하는 것입니다.
 RGB가 뒤에서 임계 값이되는 방법을 살펴 보겠습니다.
 이것은 우리가오고있는 효과가 아니라 마스크 적용 방법에 대한 감각을주기위한 것이므로 계속 사용하겠습니다.
 그래서 여기에이 임계 값에 대한 몇 가지 매개 변수를 선택했습니다. 이것은 내가 전경에 사용할 것입니다.
 다음으로, 저는 전경에서만 효과를 적용하고 있습니다. 그래서이 특별한 경우에는 모든 이미지를 회색조로 바꾸고 약간의 명암비가있는 핵심 이미지 사진 효과 노아를 사용하고 있습니다.
 나는 약간의 이미지를 채도 감소시키고 콘트라스트를 훨씬 더 늘리는 것뿐만 아니라 노출 조정을하고있다.
 출력을 살펴 보겠습니다.
 이것은 제가 사용할 전경이 될 것입니다. 여기서 제가하고 싶은 것은이 전경을 배경으로 합성해야하는 깊이 데이터 마스크를 이용하는 것입니다.
 원래 이미지의 어두운 버전 인 배경을 생성 해 봅시다.
 코어 이미지 필터 blendWithMask를 사용하여이 둘을 합성 할 수 있습니다. 바로 결과가 있습니다. 간단합니다.
 괜찮아.
 고맙습니다.
 좋아요. 자네가 보았 듯이, 클리핑, 매끄럽게하기, 그리고 그렇게하는 등의 매개 변수로 약간의 조작이 필요했습니다.
 인물 효과 매트를 사용하면 실제로 많은 과정을 거치지 않고도이 작업을 수행 할 수 있습니다.이 작업은 정말 흥미 롭습니다.
 그래서 여기에 우리는 또한 세로 깊이와 인물 매트 정보가 포함 된 또 다른 이미지로 시작합니다. 그래서 이것들을 살펴 봅시다.
 앞서 언급했듯이, 이것은 매우 높은 품질의 전경 마스크입니다.
 그럼이 머리카락에 작물을 살펴 봅시다.
 세부 사항이 얼마나 미세한 지보세요. ​​이것은 아름답습니다.
 오른쪽에는 깊이 데이터가 효과 매트와 얼마나 거친지를 보여주는 깊이가 있습니다.
 그래서 우리는 방금 전의 것과 같은 또 다른 전경 분리 효과를 보일 것입니다. 그러나 우리는 초상화 깊이를 사용하는 대신 초상화 매트를 사용했습니다.

이전처럼 전경을 살펴 보도록하겠습니다. 그러나이 경우 전경을 약간 채도가 떨어 뜨리고 약간의 대비를 추가하고 이미지에 약간의 역 동성을 추가합니다.
 이제 배경을 생성 해 봅시다.이 경우에는 또 다른 코어 이미지 필터 인 디스크 흐림 효과를 적용하고 노출을 줄이면 상황이 매우 어두워집니다.
 하지만 여전히 약간의 배경이 남아 있습니다. 아주 희미하지만 여전히 남아 있습니다.
 그리고 다시 저는 마스크를 사용하여 CI 합성을 사용합니다.이 마스크는 마스크를 사용하여 합성 작업을 수행 할 것이며 우리는 왼쪽과 오른쪽을 사용합니다.
 이게 아름답 지 않아? 고맙습니다.
 Big Head라고 부르는 다른 훌륭한 데모를 보도록하겠습니다.
 따라서 인물 사진의 매트는 아주 미세하기 때문에 우리는 실제로 그것을 사용하는 배경과 관련하여 우리의 주제의 [들리지 않는] 크기를 바꾸는 것과 같은 일을 할 수 있습니다.
 그러니 그냥 해보자. 그리고 우리는 그것을 살거야.
 여기 왼쪽에는 입력 이미지가 있고 오른쪽에는 세로 방향 매트가 있습니다.
 그리고 내가 프레임에서 피사체의 크기를 가지고 노는 동안 피사체가 점점 작아지는 것을 알아 차릴 때 여기에서 내가 할 일은 무엇인가.
 그리고 실제로 프레임에있는 피사체에 더 많은 무게를주는 것을 알 수 있습니다.하지만 여기에 내가 좋아하는 크기를 선택한다고 말하는 것처럼 멋진 멋진 것들을 할 수도 있습니다.
 전경에 대비를 더하고 백그라운드에서 [들리지 않음]을 사용하여 가상 피사계 심도와 같은 작업을 수행하여 피사체에 더 많은 팝을 제공 할 수 있습니다.
 좋아요. 다른 이미지를 보면서 그냥 똑같은 파이프 라인을 후드 아래에서 사용하고 있기 때문에 아주 간단합니다. 인물 매트를 사용하고 전경과 배경을 흐리게하기 위해 사용합니다.
 여기에 입력 된 이미지를 다시 사용하여 크기를 변경하고 크기를 크게 변경 한 다음 약간의 명암비를 적용하여 주제에 더 집중할 수 있습니다.
 그렇게 쉽고 흥미 진진합니다.
 좋아요, 우리가 행진이라고 부르는 다른 데모를 한번 봅시다.
 나는 그것이 무엇을하는지 설명하려고하지 않을 것입니다. 단지 작동중인 필터를 살펴 보겠습니다.
 거기에 당신이 가서 재미있는 것들을 할 수 있기 때문에 우리가 할 수 있기 때문에 나는 이들 중 몇 개를 함께 꿰맬 수 있는지 알 수 있습니다.
 그러니 몇 군데에서 정말로 당신에게가는 것, 정말로 그렇게하는 것, 너무 멀리가는 것.
 정말로 흥미로운 물건.
 괜찮아.
 이 데모를위한 것입니다. 즐거웠기를 바랍니다.
 따라서 Core Image에 Python 바인딩을 사용하는 방법에 대해 더 알고 싶다면 Python의 Core Image 성능 프로토 타이핑에 대한 이번 세션에 참여하시기 바랍니다.
 오늘은 저를위한 전부입니다. TrueDepth로 실시간 비디오 효과에 대해 이야기 할 비디오 엔지니어링의 Ron을 소개해 드리겠습니다.
 여러분 감사합니다.
  에마누엘 감사합니다.
 멋진 사진 효과는 있지만 비디오는 어떨까요?
 내 이름은 Ron Sokolovsky이고 저는 비디오 엔지니어링에서 왔습니다.
 이 부분에서는 TrueDepth의 카메라를 활용하여 예를 들어 백그라운드 대체 앱과 같은 실시간 비디오로 유사한 효과를 만들 것입니다.
 이러한 효과를 내기 위해 TrueDepth 카메라에서 나오는 스트림, 특성, 모범 사례 및 문제점에 대해 심층적 인 연구를 할 것입니다.
 풍부한 깊이 정보를 처리하고 렌더링하는 완전히 다른 방식 인 점군으로 작업하는 방법을 보여줄 것입니다.
 그리고 백그라운드 대체라는 앱을 백 드롭이라고 부르며 단계별로 만드는 방법을 보여 드리겠습니다.
 하지만 우선 먼저 TrueDepth의 카메라 스트림은 프레임으로 구성되며, 각 프레임은 깊이 맵, 각 픽셀에 깊이 정보 또는 해당 방향으로 장면까지의 거리가 포함 된 2D 이미지입니다.
 특정 색 구성표를 선택했습니다. 닫힌 픽셀은 빨간색으로 표시되고 빨간색 픽셀은 파란색으로 표시됩니다.
 그 사이에는 다채로운 스펙트럼이있어 깊이 맵의 질감을 볼 수 있습니다.
 검은 색 픽셀도 있는데, 깊이 맵에 구멍이 있습니다.
 이러한 픽셀의 경우 깊이가 무엇인지 알 수 없습니다.
 우리는 오늘이 스트림을 탐색 할 수있는 새로운 도구 인 샘플 응용 프로그램을 출시하고 TrueDepth Streamer라고 부릅니다.
 비디오 스트림과 TrueDepth 스트림 사이를 슬라이드 할 수 있습니다.
 TrueDepth 카메라는 어둠 속에서도 활성 조명을 사용하기 때문에 비디오는 검은 색으로 처리되기 때문에 TrueDepth 카메라의 경우처럼 정상적으로 작동합니다.
 그래서 지금 당신은 나를보고 당신은하지 않습니다.
 그렇다면 TrueDepth 카메라의 스트림을 응용 프로그램에 어떻게 추가합니까? 글쎄 네가 물어 줘서 다행이다.
 가장 먼저해야 할 일은 내장 된 TrueDepth 카메라를 발견 한 다음 장치 캡처 입력을 초기화하는 것입니다.
 그리고 세션에 깊이 데이터 출력을 추가합니다.
 이제 세션을 시작할 수 있으며 세션과 함께 TrueDepth 스트림을 사용할 수 있습니다.
 이 스트림은 두 가지 형태의 데이터, 불일치 또는 심도로 나타날 수 있습니다.

이제 불일치는 깊이의 역수이고 반대의 경우도 있으므로 어느 쪽을 선택해야합니까? 음의 불일치는 대개 기계 학습 응용 프로그램의 경우 더 나은 결과를 산출하지만, 깊이 데이터는 실제 측정의 관점에서 더 의미가 있습니다.
 깊은 심도가 깊이 제곱으로 진행되는 심도로 작업하는 경우 알아 두십시오.
 즉, 1 미터의 물체는 2 미터의 물체의 깊이 정확도의 4 배가됩니다.
 우리는 두 가지 스트림, 비디오 및 깊이를 가지고 있으며 반드시 동일한 해상도를 공유하지는 않습니다.
 TrueDepth의 카메라 해상도는 VGA 또는 640x480이며 4 : 3의 종횡비의 비디오 사전 설정을 선택하면 얻을 수 있습니다.
 그러나 종횡비 16x9를 선택하면 640x360의 깊이 맵을 얻을 수 있습니다.
 두 경우 모두 깊이 맵은 RGB 이미지의 전체 시야를 포함합니다.
 이제 비디오 응용 프로그램에 대해 이야기하고 있습니다. 따라서 많은 숫자를 매우 빠르게 처리하고 있으며 시간이 지남에 따라 시스템 압력이 발생할 수 있습니다.
 따라서 응용 프로그램을 테스트하고 공칭에서 공정, 심각, 임계 및 종료로가는 시스템 압력 수준을 측정 할 수 있습니다.
 시스템은 시스템을 종료 할 때까지 모든 작업을 수행 할 수있게 해주므로 모든 책임은 사용자에게 있습니다.
 당신이 할 수있는 또 다른 일은 감쇠 방식을 채택하는 것입니다. 압력 수준이 심각 해지면 프레임 속도를 초당 15 프레임으로 줄이거 나 30, 24, 20 및 15 프레임에서 완만하게 저하되는 더 정교한 구성을 선택할 수 있습니다 언제든지 압력 수준이 증가합니다.
 그래서 우리는 깊이 맵에 구멍이 있습니다. 우리는 그것에 대해 무엇을 할 수 있습니까? 글쎄, 사실 당신은 이미 당신을 위해 필터링 된 스트림을 얻을 수 있습니다.
 isFilteringEnabled라는 매개 변수가 있으며 기본값은 true로 설정됩니다. 즉 필터링 된 깊이 맵을 공간적 및 시간적으로 부드럽게 가져오고 구멍이 RGB 이미지에서 채워지는 것을 의미합니다.
 깊이 값을 얻는 픽셀을 쿼리 할 때마다 알기 때문에 특히 사진 및 세분화 응용 프로그램에 유용합니다.
 TrueDepth Streamer에서는 필터 스트림으로 전환하여 더 부드럽고 구멍이 채워지는 것을 확인할 수 있습니다.
 따라서이 방법은 훌륭하지만 유스 케이스의 100 %에는 적용 할 수 없습니다.
 포인트 클라우드 또는 실제 측정의 유형으로 작업하는 경우 가장 충실한 원시 데이터를 유지하는 것이 좋습니다.
 당신은 구멍이있을 것이고, 0으로 표시된 픽셀을 갖게 될 것입니다. 카메라에서 0 미터 떨어진 거리라는 의미는 아닙니다. 단지 카메라에 대한 정보가 없다는 것을 의미합니다.
 따라서 평균값과 다운 샘플링과 같은 연산을주의해야합니다. 실제 값을 0으로 섞어서는 안되기 때문입니다.
 그런데 왜 우리가 구멍을 뚫을까요? TrueDepth 카메라는 약 5m 거리까지 물체를 감지하지만 모든 물체가 동일하게 만들어진 것은 아닙니다.
 일부 재료는 낮은 반사율을 가지고 있습니다.
 그들은 대부분의 빛을 흡수합니다.
 예를 들어이 극단적 인 시나리오는 매우 낮은 반사 패브릭으로 깊이 맵으로 전환 할 때 어떤 일이 일어나는지보고합니다.
 현장에 거리가 먼 물체가 있어도 대부분의 빛을 흡수하기 때문에이 천에 홀이 형성되는 것을 볼 수 있습니다.
 필터링 된 스트림으로 전환하고 동일한 동작을 반복하면 해당 구멍이 채워집니다.
 그러나 반사되는 빛의 양에 대해서뿐만 아니라 반사되는 방향에 대해서도 마찬가지입니다.
 일부 재료는 경면 또는 반짝이며 매우 까다롭고 까다롭기 때문에 어느 방향으로 빛을 돌려 보냅니다.
 극단적 인 시나리오는이 디스플레이가 될 것이고 반사를보기 위해 비디오 스트림을 볼 수 있습니다.
 깊이 맵으로 전환하면 장치와 화면 사이의 각도에 따라 구멍이 형성됩니다.
 필터링 된 스트림으로 전환하면 구멍이 채워지지만 충실도는 떨어집니다.
 또 다른 도전 시나리오는 실외입니다. 일반적으로 실외 장면에서는 배경이 너무 멀리 떨어져 있으므로 배경에 어떤 깊이도 기대할 수 없습니다.
 또한, 태양은 활동적인 조명에 대한 공격자의 역할을합니다.
 내가 햇볕이 잘 드는 오후에 밖에 나갔다는 것을 증명하기 위해, 태양에 맞서 자신을 배치했다.
 그리고 깊이 맵으로 전환 할 때 배경에 깊이가없는 것을 볼 수 있습니다. 프레임 주위에 구멍이 생깁니다. 특히이 경우에는 머리카락이 좋습니다.
 그러나 전경에있는 대부분의 깊이는 그대로이며 매우 유용합니다.
 구멍을 확보하기 위해 마지막으로 한 가지 요점은 TrueDepth 카메라의 관점에서 볼 때 투사 된 빛의 일부가 뒤로 물체를 때리면 프로젝터와 카메라 사이의 시차에서 그림자가 생기는 것입니다.
 이 찻잔의 오른쪽에있는 예를 볼 수 있지만 여기에는 다른 것이 있습니다.
 이것은 깊이 맵이 아니므로 왜 우리는 구멍을 차지합니까? TrueDepth Streamer에서는 2-D 모드에서 3-D 모드로 전환 할 수 있으므로 점군보기가 가능합니다.

점 구름을 사용하면 장면의 시점을 동적으로 변경할 수 있으므로 우리는 더 많은 구멍을 만듭니다.
 그리고 이제 저는이 찻잔이 비어 있거나 반쯤 찼다는 것을 물어볼 수 있습니다. 대답은 우리가 전혀 모른다는 것입니다.
 사실상 카메라의 시점을 변경함으로써 우리는 새로운 정보를 추가하지 않으며 TrueDepth 카메라는 많은 일을 할 수 있지만 그 중 하나가 아닌 머그잔으로 빛을 굴절시키기 때문입니다.
 이 라이브를 보자.
 그래서 저는 비디오 뷰로 시작하고 당신이이 구석을 바라보기를 바랍니다.
 화면을 터치하면 무슨 일이 일어나는지보고, 내 이마를 만지면 깊이 표시를 볼 수 있습니다.
 그리고 전화기를 움직이면 당신은 [들리지 않는] 변화를 볼 수 있습니다. 내가 할 수있는 이유는 TrueDepth 카메라의 스트림이 실행 중이며 비디오에 오버레이 된 것을 볼 수 있기 때문입니다.
 따라서 우리는이 라이브 스트림을 초당 30 프레임을 가지고 필터링 된 스트림으로 전환 한 다음 모든 구멍을 채 웁니다.
 포인트 클라우드 뷰로 전환하면 뷰의 시점을 장면으로 동적으로 변경할 수 있습니다.
 그래서 내가 장치를 직접보고있을지라도 누군가가 나를 위로 바라 보는 것처럼 보입니다.
 이제 이것을 점 구름이라고 부르는 이유는 3 차원 공간에서 실제로 점을 볼 수있게 확대하면됩니다.
 그러나 WWDC에서 당신과 함께하면서 나는 사물을 원근감있게 되돌리기 위해 자신을 꼬집어 야한다고 생각합니다.
 그래서 구름을 가리 키도록 해주셔서 감사합니다.
 어떻게 우리가 그들을 창조할까요? 깊이 Z가 픽셀 좌표 U와 V의 함수 인 2 차원 이미지 인 깊이 맵부터 시작합니다.
 그리고 우리는 그것을 3D 공간 X, Y, Z에서 새로운 좌표계로 변환하려고합니다.
 이제 우리는 이미 Z 좌표를 가지고 있습니다, 그것은 깊이 맵으로부터의 깊이입니다. 그러나 우리는 X와 Y를 얻고 싶습니다.
 이를 위해서는 초점 거리와 주요 점에 대한 정보가있는 내장 스크립트에서 도움을 얻을 필요가 있습니다.
 예를 들어 X를 얻으려면 픽셀 좌표 U로 시작하고 주 포인트를 빼고 깊이를 곱한 다음 초점 길이로 나눠야합니다.
 그리고 당연히 다른 차원에서도 똑같은 일을해야합니다.
 이제이 내장 함수 행렬은 카메라 보정 데이터를 통해 액세스 할 수 있습니다.
 실제로이 작업은 TrueDepth 스트림의 모든 프레임에서 수행됩니다.
 그 이유는 비디오 스트림과 깊이 스트림이 두 개의 개별 카메라에서 나옵니다.
 그러나 TrueDepth 카메라는 깊이 맵을 제공하기 때문에 포인트 클라우드로 변환하고 RGB 이미지의 시점으로 다시 투영 할 수 있으므로 깊이 스트림이 이미 비디오 스트림에 등록되어 RGBD 데이터를 얻습니다.
 자, 고마워.
 예, 꽤 멋지 네요.
 이제 이러한 유형의 작업은 금속 그래픽 쉐이더에서 가장 잘 수행됩니다.
 TrueDepth Streamer의 코드를 다운로드하면 두 영역에 집중할 수 있습니다.
 버텍스 쉐이더에서는 점의 위치를 ​​제어하기 때문에 깊이 맵으로 시작하여이를 실제 좌표 또는 X, Y, Z로 변환합니다.
 그런 다음 관점을 장면으로 바꾸기 위해 뷰 행렬을 곱할 수 있습니다.
 프래그먼트 쉐이더에서 꼭지점의 출력을 얻지 만, 깊이 맵에서 실제 값이나 구멍인지 확인해야합니다.
 구멍이라면 0으로 표시되어 깊이를 알 수 없기 때문에 X, Y, Z로 변환 할 수 없으므로이 점을 무시해야합니다.
 이것이 실제 값이라면 RGB 텍스처를 샘플링하고이 경우 조각이나 점에 색상을 추가 할 수 있습니다.
 그래서 저는이 부분이 조금 기술적이었고 많은 사람들이 다른 배경에서 왔음을 이해합니다.
 우리가 당신을위한 앱을 가지고 있을지도 모른다는 두려움, 당신의 배경을 대체 할 앱, 그것이 살아 있는지 보자.
 살아 보자.
 그래서 나는 요세미티에 자신을 넣을 수 있습니다, 나는 더 추상적 인 것에 자신을 집어 넣을 수 있습니다.
 나는 애리조나 주 영양 캐년까지가는 길조차 갈 수 있는데 지난 번 거기에 도착하는 데 15 시간이 걸렸습니다. 방금 스틱을 밟아 가스에 많은 돈을 절약 할 수있었습니다.
 실제로,이 응용 프로그램은 누구도 스트리밍을들을 수없는 공간에 놓을 수 있습니다.
 그럼 우리가 어떻게 그걸 만들까요? 비디오 애플리케이션을 다룰 때마다 프레임 단위로 진행되는 다른 작업이 있습니다.이 경우 얼굴을 탐지하고 깊이 맵에서 새로운 마스크를 작성하고 RGB 해상도로 부드럽게 늘리십시오. .
 그리고 나서이 전경 마스크를 가져 와서 저조도 배경 이미지로 다시 상향 조정합니다.
 그리고 나서 우리는 그것들을 혼합하거나 들여다 볼 수 있지만, 복잡성을 줄이기 위해 할 수있는 일이 있습니다.
 우리가 배경 이미지를로드 할 때마다 프레임 당 1 회 RGB 해상도로 크기를 조정하면 두 번째 고화질이 필요하지 않으며 블렌딩이 큰 차이를 만드는 저해상도에서 수행됩니다.
 그럼 그 깊이에 깊이 잠입하십시오.
 우리가 가장 먼저 필요한 것은 얼굴의 중심을 찾는 것입니다.
 그리고 iOS에는 실제로 얼굴 메타 데이터를 얻을 수있는 몇 가지 방법이 있습니다.
 코어 이미지 검출기 또는 Vision Framework를 사용할 수 있지만,이 경우에는 얼굴 중앙에 픽셀이 필요하므로 AV 메타 데이터 객체 유형의 얼굴을 사용할 수 있습니다.

그러나 이것은 RGB 이미지의 코딩 시스템에서 중심을 제공하며 동일한 해상도가 아닐 수있는 깊이 맵에 맵핑해야합니다.
 얼굴의 깊이 값을 얻은 후에는 깊이 맵을 임계 값 25 센티미터의 여백에 더하여 사용할 수 있고 이진 마스크를 만듭니다. 전경은 하나이고 배경은 0입니다.
 실제로 여기서 멈출 수 있습니다.이 바이너리 마스크를 사용하여 효과를 만들 수 있습니다.
 배경에서 전경으로의 전환은 매우 날카 로울 것입니다. 그러나 우리는 가장자리 주위에 어떤 문제를 일으킬 것입니다.
 그래서 우리는 그것을 조금 필터링하고 싶습니다.
 첫 번째 단계는 백그라운드에서 전경 (이 경우 Gaussian Blurring)으로 약간의 스무딩을 적용하는 것입니다.
 가우시안 블러 링의 반경은 전환의 기울기를 결정하며 값을 사용하여 다양한 효과를 얻을 수 있습니다.
 우리가 추가하는 또 다른 처리 단계는 감마 조정입니다.이 전환을 배경에서 전경으로 미세 조정할 수 있습니다.
 감마 값을 1보다 높게 설정하면 전경 마스크가 좁아집니다.
 반면에 우리가 1보다 작은 감마 값을 사용하면보다 넓은 전경 마스크와 약간의 아우라를 얻을 수 있습니다.
 따라서 두 매개 변수를 결합하여 다른 효과를 만들 수 있습니다.
 큰 흐림 반경과 큰 감마 값을 사용하면 공간의 홀로그램 인 것처럼 보일 수있는이 투명한 전환을 만들면 수중이 될 수 있고 값을 사용하여 다양한 효과를 낼 수 있습니다.
 반경을 높게 유지하고 감마 값을 매우 낮은 숫자로 줄이면 머리 주위에이 후광을 만듭니다.
 따라서 자신 만의 효과를 내기 위해 이걸 가지고 놀 수 있습니다.
 이것을 어떻게 구현합니까? Core Image에서는 매우 간단합니다. 세 개의 필터를 연속해서 연결할 수 있습니다.
 가우스 블러 (Gaussian Blur)로 시작하여 감마 조정을 추가하고 RGB 해상도로 상향 조정합니다.
 그러나 모범 사례로 강조하고자하는 몇 가지 작은 점이 있습니다.
 가우시안 블러 링 (Gaussian Blurring)과 같은 길쌈 기반 작업으로 작업 할 때마다 최상의 방법은 범위를 좁히는 것으로 시작하는 것입니다.
 테두리 픽셀을 바깥쪽으로 반복함으로써 이미지의 모든 테두리가 필터로 올바르게 처리되도록 할 수 있습니다.
 또한 필터링 후 및 업 스케일링 직전에 최선의 방법은 원래의 범위로 되돌아가는 것입니다. 왜냐하면 이것이 우리가 정말로 신경을 쓰는 이미지의 일부이기 때문입니다.
 이 시점에서 우리는 전경의 알파 매트를 가지고 있으며 그것을 사용하여 상반기에 Emmanuel이 보여준 것처럼 배경과 전경에 대한 다양한 종류의 효과를 만들 수 있습니다.
 Backdrop에서는 TrueDepth 카메라에서 만든 알파 매트를 사용하여 한 줄의 코어 이미지 코드에서로드 된 배경 이미지와 RGB 스트림을 혼합하여이 배경 대체 효과를 만듭니다.
 따라서 TrueDepth 카메라는 이미 비디오 스트림에 등록 된 초당 30 프레임의 640x480 깊이 맵의 해상도를 제공합니다.
 이를 사용하여 점 구름을 만들고 장면의 시점을 동적으로 변경하거나 필터 깊이를 사용하여 다양한 종류의 비디오 효과를 만들 수 있습니다.
 웹 페이지로 이동하여 목성 노트 TrueDepth Streamer 및 Backdrop을 다운로드하면 응용 프로그램에서 만들 수있는 많은 새로운 멋진 비디오 효과의 시작점으로 활용할 수 있기를 바랍니다.
 AVCapture 연구소에서 인사 해 주셔서 대단히 감사합니다.
 좋은 하루 되세요.
